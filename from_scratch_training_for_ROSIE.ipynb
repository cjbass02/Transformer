{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Scratch Transformer Training Loop\n",
    "\n",
    "I wanted to train this on MSOE's supercomputer, and the FAST API was firewalled, so everything is done in line here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n",
      "Epoch 1/100 — Step 500 — Loss: 3.3555\n",
      "Epoch 1/100 — Step 1000 — Loss: 3.2190\n",
      "Epoch 1/100 — Step 1500 — Loss: 3.3403\n",
      "Epoch 1/100 — Step 2000 — Loss: 3.2694\n",
      "Epoch 1/100 — Step 2500 — Loss: 3.1624\n",
      "Epoch 1/100 — Step 3000 — Loss: 3.4571\n",
      "Epoch 1/100 — Step 3500 — Loss: 3.1899\n",
      "Epoch 1/100 — Step 4000 — Loss: 3.1134\n",
      "Epoch 1/100 — Step 4500 — Loss: 3.5758\n",
      "Epoch 1/100 — Step 5000 — Loss: 3.2992\n",
      "Epoch 1/100 — Step 5500 — Loss: 3.2125\n",
      "Epoch 1/100 — Step 6000 — Loss: 3.1928\n",
      "Epoch 1/100 — Step 6500 — Loss: 3.2861\n",
      "Epoch 1/100 — Step 7000 — Loss: 3.1983\n",
      "Epoch 1/100 — Step 7500 — Loss: 3.2270\n",
      "Epoch 1/100 — Step 8000 — Loss: 3.3423\n",
      "Epoch 1/100 — Step 8500 — Loss: 3.4643\n",
      "Epoch 1/100 — Step 9000 — Loss: 3.4991\n",
      "Epoch 1/100 — Step 9500 — Loss: 3.2510\n",
      "Epoch 1/100 — Step 10000 — Loss: 3.5278\n",
      "Epoch 1/100 — Step 10500 — Loss: 3.0059\n",
      "Epoch 1/100 — Step 11000 — Loss: 3.3667\n",
      "Epoch 1/100 — avg_loss: 3.2788, accuracy: 15.25%\n",
      "Epoch 2/100 — Step 500 — Loss: 3.2733\n",
      "Epoch 2/100 — Step 1000 — Loss: 3.1219\n",
      "Epoch 2/100 — Step 1500 — Loss: 3.2648\n",
      "Epoch 2/100 — Step 2000 — Loss: 3.1913\n",
      "Epoch 2/100 — Step 2500 — Loss: 3.0656\n",
      "Epoch 2/100 — Step 3000 — Loss: 3.4313\n",
      "Epoch 2/100 — Step 3500 — Loss: 3.1117\n",
      "Epoch 2/100 — Step 4000 — Loss: 3.0335\n",
      "Epoch 2/100 — Step 4500 — Loss: 3.4825\n",
      "Epoch 2/100 — Step 5000 — Loss: 3.2264\n",
      "Epoch 2/100 — Step 5500 — Loss: 3.1500\n",
      "Epoch 2/100 — Step 6000 — Loss: 3.1205\n",
      "Epoch 2/100 — Step 6500 — Loss: 3.2246\n",
      "Epoch 2/100 — Step 7000 — Loss: 3.1261\n",
      "Epoch 2/100 — Step 7500 — Loss: 3.1749\n",
      "Epoch 2/100 — Step 8000 — Loss: 3.2564\n",
      "Epoch 2/100 — Step 8500 — Loss: 3.3931\n",
      "Epoch 2/100 — Step 9000 — Loss: 3.3868\n",
      "Epoch 2/100 — Step 9500 — Loss: 3.1602\n",
      "Epoch 2/100 — Step 10000 — Loss: 3.3783\n",
      "Epoch 2/100 — Step 10500 — Loss: 2.9334\n",
      "Epoch 2/100 — Step 11000 — Loss: 3.2974\n",
      "Epoch 2/100 — avg_loss: 3.1860, accuracy: 16.93%\n",
      "Epoch 3/100 — Step 500 — Loss: 3.1860\n",
      "Epoch 3/100 — Step 1000 — Loss: 3.0032\n",
      "Epoch 3/100 — Step 1500 — Loss: 3.1736\n",
      "Epoch 3/100 — Step 2000 — Loss: 3.1103\n",
      "Epoch 3/100 — Step 2500 — Loss: 2.9542\n",
      "Epoch 3/100 — Step 3000 — Loss: 3.3822\n",
      "Epoch 3/100 — Step 3500 — Loss: 3.0189\n",
      "Epoch 3/100 — Step 4000 — Loss: 2.9238\n",
      "Epoch 3/100 — Step 4500 — Loss: 3.3745\n",
      "Epoch 3/100 — Step 5000 — Loss: 3.1204\n",
      "Epoch 3/100 — Step 5500 — Loss: 3.0741\n",
      "Epoch 3/100 — Step 6000 — Loss: 3.0245\n",
      "Epoch 3/100 — Step 6500 — Loss: 3.1677\n",
      "Epoch 3/100 — Step 7000 — Loss: 3.0373\n",
      "Epoch 3/100 — Step 7500 — Loss: 3.1147\n",
      "Epoch 3/100 — Step 8000 — Loss: 3.1497\n",
      "Epoch 3/100 — Step 8500 — Loss: 3.2998\n",
      "Epoch 3/100 — Step 9000 — Loss: 3.2681\n",
      "Epoch 3/100 — Step 9500 — Loss: 3.0544\n",
      "Epoch 3/100 — Step 10000 — Loss: 3.2207\n",
      "Epoch 3/100 — Step 10500 — Loss: 2.8703\n",
      "Epoch 3/100 — Step 11000 — Loss: 3.2212\n",
      "Epoch 3/100 — avg_loss: 3.0859, accuracy: 19.27%\n",
      "Epoch 4/100 — Step 500 — Loss: 3.0945\n",
      "Epoch 4/100 — Step 1000 — Loss: 2.8804\n",
      "Epoch 4/100 — Step 1500 — Loss: 3.0732\n",
      "Epoch 4/100 — Step 2000 — Loss: 3.0393\n",
      "Epoch 4/100 — Step 2500 — Loss: 2.8533\n",
      "Epoch 4/100 — Step 3000 — Loss: 3.3218\n",
      "Epoch 4/100 — Step 3500 — Loss: 2.9217\n",
      "Epoch 4/100 — Step 4000 — Loss: 2.8100\n",
      "Epoch 4/100 — Step 4500 — Loss: 3.2597\n",
      "Epoch 4/100 — Step 5000 — Loss: 3.0165\n",
      "Epoch 4/100 — Step 5500 — Loss: 2.9938\n",
      "Epoch 4/100 — Step 6000 — Loss: 2.9226\n",
      "Epoch 4/100 — Step 6500 — Loss: 3.1183\n",
      "Epoch 4/100 — Step 7000 — Loss: 2.9506\n",
      "Epoch 4/100 — Step 7500 — Loss: 3.0658\n",
      "Epoch 4/100 — Step 8000 — Loss: 3.0455\n",
      "Epoch 4/100 — Step 8500 — Loss: 3.2001\n",
      "Epoch 4/100 — Step 9000 — Loss: 3.1537\n",
      "Epoch 4/100 — Step 9500 — Loss: 2.9574\n",
      "Epoch 4/100 — Step 10000 — Loss: 3.0837\n",
      "Epoch 4/100 — Step 10500 — Loss: 2.8104\n",
      "Epoch 4/100 — Step 11000 — Loss: 3.1483\n",
      "Epoch 4/100 — avg_loss: 2.9906, accuracy: 20.92%\n",
      "Epoch 5/100 — Step 500 — Loss: 3.0211\n",
      "Epoch 5/100 — Step 1000 — Loss: 2.7754\n",
      "Epoch 5/100 — Step 1500 — Loss: 2.9734\n",
      "Epoch 5/100 — Step 2000 — Loss: 2.9903\n",
      "Epoch 5/100 — Step 2500 — Loss: 2.7794\n",
      "Epoch 5/100 — Step 3000 — Loss: 3.2611\n",
      "Epoch 5/100 — Step 3500 — Loss: 2.8393\n",
      "Epoch 5/100 — Step 4000 — Loss: 2.7223\n",
      "Epoch 5/100 — Step 4500 — Loss: 3.1623\n",
      "Epoch 5/100 — Step 5000 — Loss: 2.9266\n",
      "Epoch 5/100 — Step 5500 — Loss: 2.9218\n",
      "Epoch 5/100 — Step 6000 — Loss: 2.8318\n",
      "Epoch 5/100 — Step 6500 — Loss: 3.0605\n",
      "Epoch 5/100 — Step 7000 — Loss: 2.8825\n",
      "Epoch 5/100 — Step 7500 — Loss: 3.0282\n",
      "Epoch 5/100 — Step 8000 — Loss: 2.9528\n",
      "Epoch 5/100 — Step 8500 — Loss: 3.1115\n",
      "Epoch 5/100 — Step 9000 — Loss: 3.0575\n",
      "Epoch 5/100 — Step 9500 — Loss: 2.8799\n",
      "Epoch 5/100 — Step 10000 — Loss: 2.9715\n",
      "Epoch 5/100 — Step 10500 — Loss: 2.7496\n",
      "Epoch 5/100 — Step 11000 — Loss: 3.0846\n",
      "Epoch 5/100 — avg_loss: 2.9137, accuracy: 22.06%\n",
      "Epoch 6/100 — Step 500 — Loss: 2.9666\n",
      "Epoch 6/100 — Step 1000 — Loss: 2.6940\n",
      "Epoch 6/100 — Step 1500 — Loss: 2.8793\n",
      "Epoch 6/100 — Step 2000 — Loss: 2.9563\n",
      "Epoch 6/100 — Step 2500 — Loss: 2.7291\n",
      "Epoch 6/100 — Step 3000 — Loss: 3.2060\n",
      "Epoch 6/100 — Step 3500 — Loss: 2.7749\n",
      "Epoch 6/100 — Step 4000 — Loss: 2.6584\n",
      "Epoch 6/100 — Step 4500 — Loss: 3.0834\n",
      "Epoch 6/100 — Step 5000 — Loss: 2.8554\n",
      "Epoch 6/100 — Step 5500 — Loss: 2.8676\n",
      "Epoch 6/100 — Step 6000 — Loss: 2.7578\n",
      "Epoch 6/100 — Step 6500 — Loss: 3.0018\n",
      "Epoch 6/100 — Step 7000 — Loss: 2.8301\n",
      "Epoch 6/100 — Step 7500 — Loss: 2.9919\n",
      "Epoch 6/100 — Step 8000 — Loss: 2.8775\n",
      "Epoch 6/100 — Step 8500 — Loss: 3.0382\n",
      "Epoch 6/100 — Step 9000 — Loss: 2.9863\n",
      "Epoch 6/100 — Step 9500 — Loss: 2.8230\n",
      "Epoch 6/100 — Step 10000 — Loss: 2.8811\n",
      "Epoch 6/100 — Step 10500 — Loss: 2.6945\n",
      "Epoch 6/100 — Step 11000 — Loss: 3.0300\n",
      "Epoch 6/100 — avg_loss: 2.8550, accuracy: 22.78%\n",
      "Epoch 7/100 — Step 500 — Loss: 2.9222\n",
      "Epoch 7/100 — Step 1000 — Loss: 2.6330\n",
      "Epoch 7/100 — Step 1500 — Loss: 2.7971\n",
      "Epoch 7/100 — Step 2000 — Loss: 2.9272\n",
      "Epoch 7/100 — Step 2500 — Loss: 2.6935\n",
      "Epoch 7/100 — Step 3000 — Loss: 3.1599\n",
      "Epoch 7/100 — Step 3500 — Loss: 2.7244\n",
      "Epoch 7/100 — Step 4000 — Loss: 2.6122\n",
      "Epoch 7/100 — Step 4500 — Loss: 3.0156\n",
      "Epoch 7/100 — Step 5000 — Loss: 2.8041\n",
      "Epoch 7/100 — Step 5500 — Loss: 2.8289\n",
      "Epoch 7/100 — Step 6000 — Loss: 2.7004\n",
      "Epoch 7/100 — Step 6500 — Loss: 2.9491\n",
      "Epoch 7/100 — Step 7000 — Loss: 2.7878\n",
      "Epoch 7/100 — Step 7500 — Loss: 2.9575\n",
      "Epoch 7/100 — Step 8000 — Loss: 2.8192\n",
      "Epoch 7/100 — Step 8500 — Loss: 2.9777\n",
      "Epoch 7/100 — Step 9000 — Loss: 2.9366\n",
      "Epoch 7/100 — Step 9500 — Loss: 2.7820\n",
      "Epoch 7/100 — Step 10000 — Loss: 2.8097\n",
      "Epoch 7/100 — Step 10500 — Loss: 2.6496\n",
      "Epoch 7/100 — Step 11000 — Loss: 2.9841\n",
      "Epoch 7/100 — avg_loss: 2.8096, accuracy: 23.20%\n",
      "Epoch 8/100 — Step 500 — Loss: 2.8832\n",
      "Epoch 8/100 — Step 1000 — Loss: 2.5860\n",
      "Epoch 8/100 — Step 1500 — Loss: 2.7302\n",
      "Epoch 8/100 — Step 2000 — Loss: 2.9007\n",
      "Epoch 8/100 — Step 2500 — Loss: 2.6661\n",
      "Epoch 8/100 — Step 3000 — Loss: 3.1236\n",
      "Epoch 8/100 — Step 3500 — Loss: 2.6846\n",
      "Epoch 8/100 — Step 4000 — Loss: 2.5802\n",
      "Epoch 8/100 — Step 4500 — Loss: 2.9557\n",
      "Epoch 8/100 — Step 5000 — Loss: 2.7677\n",
      "Epoch 8/100 — Step 5500 — Loss: 2.8014\n",
      "Epoch 8/100 — Step 6000 — Loss: 2.6579\n",
      "Epoch 8/100 — Step 6500 — Loss: 2.9040\n",
      "Epoch 8/100 — Step 7000 — Loss: 2.7527\n",
      "Epoch 8/100 — Step 7500 — Loss: 2.9273\n",
      "Epoch 8/100 — Step 8000 — Loss: 2.7732\n",
      "Epoch 8/100 — Step 8500 — Loss: 2.9269\n",
      "Epoch 8/100 — Step 9000 — Loss: 2.9013\n",
      "Epoch 8/100 — Step 9500 — Loss: 2.7526\n",
      "Epoch 8/100 — Step 10000 — Loss: 2.7531\n",
      "Epoch 8/100 — Step 10500 — Loss: 2.6149\n",
      "Epoch 8/100 — Step 11000 — Loss: 2.9465\n",
      "Epoch 8/100 — avg_loss: 2.7738, accuracy: 23.49%\n",
      "Epoch 9/100 — Step 500 — Loss: 2.8488\n",
      "Epoch 9/100 — Step 1000 — Loss: 2.5485\n",
      "Epoch 9/100 — Step 1500 — Loss: 2.6776\n",
      "Epoch 9/100 — Step 2000 — Loss: 2.8772\n",
      "Epoch 9/100 — Step 2500 — Loss: 2.6438\n",
      "Epoch 9/100 — Step 3000 — Loss: 3.0962\n",
      "Epoch 9/100 — Step 3500 — Loss: 2.6522\n",
      "Epoch 9/100 — Step 4000 — Loss: 2.5588\n",
      "Epoch 9/100 — Step 4500 — Loss: 2.9030\n",
      "Epoch 9/100 — Step 5000 — Loss: 2.7404\n",
      "Epoch 9/100 — Step 5500 — Loss: 2.7821\n",
      "Epoch 9/100 — Step 6000 — Loss: 2.6271\n",
      "Epoch 9/100 — Step 6500 — Loss: 2.8660\n",
      "Epoch 9/100 — Step 7000 — Loss: 2.7230\n",
      "Epoch 9/100 — Step 7500 — Loss: 2.9018\n",
      "Epoch 9/100 — Step 8000 — Loss: 2.7356\n",
      "Epoch 9/100 — Step 8500 — Loss: 2.8836\n",
      "Epoch 9/100 — Step 9000 — Loss: 2.8746\n",
      "Epoch 9/100 — Step 9500 — Loss: 2.7314\n",
      "Epoch 9/100 — Step 10000 — Loss: 2.7067\n",
      "Epoch 9/100 — Step 10500 — Loss: 2.5885\n",
      "Epoch 9/100 — Step 11000 — Loss: 2.9163\n",
      "Epoch 9/100 — avg_loss: 2.7449, accuracy: 23.74%\n",
      "Epoch 10/100 — Step 500 — Loss: 2.8186\n",
      "Epoch 10/100 — Step 1000 — Loss: 2.5179\n",
      "Epoch 10/100 — Step 1500 — Loss: 2.6364\n",
      "Epoch 10/100 — Step 2000 — Loss: 2.8567\n",
      "Epoch 10/100 — Step 2500 — Loss: 2.6254\n",
      "Epoch 10/100 — Step 3000 — Loss: 3.0759\n",
      "Epoch 10/100 — Step 3500 — Loss: 2.6249\n",
      "Epoch 10/100 — Step 4000 — Loss: 2.5445\n",
      "Epoch 10/100 — Step 4500 — Loss: 2.8569\n",
      "Epoch 10/100 — Step 5000 — Loss: 2.7180\n",
      "Epoch 10/100 — Step 5500 — Loss: 2.7684\n",
      "Epoch 10/100 — Step 6000 — Loss: 2.6043\n",
      "Epoch 10/100 — Step 6500 — Loss: 2.8339\n",
      "Epoch 10/100 — Step 7000 — Loss: 2.6974\n",
      "Epoch 10/100 — Step 7500 — Loss: 2.8801\n",
      "Epoch 10/100 — Step 8000 — Loss: 2.7036\n",
      "Epoch 10/100 — Step 8500 — Loss: 2.8464\n",
      "Epoch 10/100 — Step 9000 — Loss: 2.8526\n",
      "Epoch 10/100 — Step 9500 — Loss: 2.7155\n",
      "Epoch 10/100 — Step 10000 — Loss: 2.6671\n",
      "Epoch 10/100 — Step 10500 — Loss: 2.5685\n",
      "Epoch 10/100 — Step 11000 — Loss: 2.8921\n",
      "Epoch 10/100 — avg_loss: 2.7211, accuracy: 23.92%\n",
      "Epoch 11/100 — Step 500 — Loss: 2.7920\n",
      "Epoch 11/100 — Step 1000 — Loss: 2.4926\n",
      "Epoch 11/100 — Step 1500 — Loss: 2.6039\n",
      "Epoch 11/100 — Step 2000 — Loss: 2.8389\n",
      "Epoch 11/100 — Step 2500 — Loss: 2.6099\n",
      "Epoch 11/100 — Step 3000 — Loss: 3.0608\n",
      "Epoch 11/100 — Step 3500 — Loss: 2.6012\n",
      "Epoch 11/100 — Step 4000 — Loss: 2.5348\n",
      "Epoch 11/100 — Step 4500 — Loss: 2.8164\n",
      "Epoch 11/100 — Step 5000 — Loss: 2.6981\n",
      "Epoch 11/100 — Step 5500 — Loss: 2.7579\n",
      "Epoch 11/100 — Step 6000 — Loss: 2.5868\n",
      "Epoch 11/100 — Step 6500 — Loss: 2.8064\n",
      "Epoch 11/100 — Step 7000 — Loss: 2.6751\n",
      "Epoch 11/100 — Step 7500 — Loss: 2.8614\n",
      "Epoch 11/100 — Step 8000 — Loss: 2.6758\n",
      "Epoch 11/100 — Step 8500 — Loss: 2.8140\n",
      "Epoch 11/100 — Step 9000 — Loss: 2.8331\n",
      "Epoch 11/100 — Step 9500 — Loss: 2.7030\n",
      "Epoch 11/100 — Step 10000 — Loss: 2.6327\n",
      "Epoch 11/100 — Step 10500 — Loss: 2.5532\n",
      "Epoch 11/100 — Step 11000 — Loss: 2.8728\n",
      "Epoch 11/100 — avg_loss: 2.7010, accuracy: 24.09%\n",
      "Epoch 12/100 — Step 500 — Loss: 2.7686\n",
      "Epoch 12/100 — Step 1000 — Loss: 2.4716\n",
      "Epoch 12/100 — Step 1500 — Loss: 2.5776\n",
      "Epoch 12/100 — Step 2000 — Loss: 2.8232\n",
      "Epoch 12/100 — Step 2500 — Loss: 2.5968\n",
      "Epoch 12/100 — Step 3000 — Loss: 3.0492\n",
      "Epoch 12/100 — Step 3500 — Loss: 2.5807\n",
      "Epoch 12/100 — Step 4000 — Loss: 2.5277\n",
      "Epoch 12/100 — Step 4500 — Loss: 2.7805\n",
      "Epoch 12/100 — Step 5000 — Loss: 2.6796\n",
      "Epoch 12/100 — Step 5500 — Loss: 2.7489\n",
      "Epoch 12/100 — Step 6000 — Loss: 2.5727\n",
      "Epoch 12/100 — Step 6500 — Loss: 2.7825\n",
      "Epoch 12/100 — Step 7000 — Loss: 2.6555\n",
      "Epoch 12/100 — Step 7500 — Loss: 2.8449\n",
      "Epoch 12/100 — Step 8000 — Loss: 2.6510\n",
      "Epoch 12/100 — Step 8500 — Loss: 2.7859\n",
      "Epoch 12/100 — Step 9000 — Loss: 2.8149\n",
      "Epoch 12/100 — Step 9500 — Loss: 2.6927\n",
      "Epoch 12/100 — Step 10000 — Loss: 2.6024\n",
      "Epoch 12/100 — Step 10500 — Loss: 2.5414\n",
      "Epoch 12/100 — Step 11000 — Loss: 2.8575\n",
      "Epoch 12/100 — avg_loss: 2.6838, accuracy: 24.26%\n",
      "Epoch 13/100 — Step 500 — Loss: 2.7479\n",
      "Epoch 13/100 — Step 1000 — Loss: 2.4540\n",
      "Epoch 13/100 — Step 1500 — Loss: 2.5560\n",
      "Epoch 13/100 — Step 2000 — Loss: 2.8093\n",
      "Epoch 13/100 — Step 2500 — Loss: 2.5854\n",
      "Epoch 13/100 — Step 3000 — Loss: 3.0400\n",
      "Epoch 13/100 — Step 3500 — Loss: 2.5629\n",
      "Epoch 13/100 — Step 4000 — Loss: 2.5220\n",
      "Epoch 13/100 — Step 4500 — Loss: 2.7485\n",
      "Epoch 13/100 — Step 5000 — Loss: 2.6620\n",
      "Epoch 13/100 — Step 5500 — Loss: 2.7405\n",
      "Epoch 13/100 — Step 6000 — Loss: 2.5608\n",
      "Epoch 13/100 — Step 6500 — Loss: 2.7612\n",
      "Epoch 13/100 — Step 7000 — Loss: 2.6383\n",
      "Epoch 13/100 — Step 7500 — Loss: 2.8301\n",
      "Epoch 13/100 — Step 8000 — Loss: 2.6286\n",
      "Epoch 13/100 — Step 8500 — Loss: 2.7615\n",
      "Epoch 13/100 — Step 9000 — Loss: 2.7975\n",
      "Epoch 13/100 — Step 9500 — Loss: 2.6837\n",
      "Epoch 13/100 — Step 10000 — Loss: 2.5755\n",
      "Epoch 13/100 — Step 10500 — Loss: 2.5319\n",
      "Epoch 13/100 — Step 11000 — Loss: 2.8453\n",
      "Epoch 13/100 — avg_loss: 2.6688, accuracy: 24.42%\n",
      "Epoch 14/100 — Step 500 — Loss: 2.7294\n",
      "Epoch 14/100 — Step 1000 — Loss: 2.4394\n",
      "Epoch 14/100 — Step 1500 — Loss: 2.5379\n",
      "Epoch 14/100 — Step 2000 — Loss: 2.7968\n",
      "Epoch 14/100 — Step 2500 — Loss: 2.5751\n",
      "Epoch 14/100 — Step 3000 — Loss: 3.0324\n",
      "Epoch 14/100 — Step 3500 — Loss: 2.5475\n",
      "Epoch 14/100 — Step 4000 — Loss: 2.5172\n",
      "Epoch 14/100 — Step 4500 — Loss: 2.7196\n",
      "Epoch 14/100 — Step 5000 — Loss: 2.6451\n",
      "Epoch 14/100 — Step 5500 — Loss: 2.7322\n",
      "Epoch 14/100 — Step 6000 — Loss: 2.5502\n",
      "Epoch 14/100 — Step 6500 — Loss: 2.7419\n",
      "Epoch 14/100 — Step 7000 — Loss: 2.6232\n",
      "Epoch 14/100 — Step 7500 — Loss: 2.8168\n",
      "Epoch 14/100 — Step 8000 — Loss: 2.6082\n",
      "Epoch 14/100 — Step 8500 — Loss: 2.7401\n",
      "Epoch 14/100 — Step 9000 — Loss: 2.7808\n",
      "Epoch 14/100 — Step 9500 — Loss: 2.6757\n",
      "Epoch 14/100 — Step 10000 — Loss: 2.5515\n",
      "Epoch 14/100 — Step 10500 — Loss: 2.5243\n",
      "Epoch 14/100 — Step 11000 — Loss: 2.8356\n",
      "Epoch 14/100 — avg_loss: 2.6555, accuracy: 24.54%\n",
      "Epoch 15/100 — Step 500 — Loss: 2.7127\n",
      "Epoch 15/100 — Step 1000 — Loss: 2.4272\n",
      "Epoch 15/100 — Step 1500 — Loss: 2.5226\n",
      "Epoch 15/100 — Step 2000 — Loss: 2.7855\n",
      "Epoch 15/100 — Step 2500 — Loss: 2.5656\n",
      "Epoch 15/100 — Step 3000 — Loss: 3.0261\n",
      "Epoch 15/100 — Step 3500 — Loss: 2.5342\n",
      "Epoch 15/100 — Step 4000 — Loss: 2.5127\n",
      "Epoch 15/100 — Step 4500 — Loss: 2.6934\n",
      "Epoch 15/100 — Step 5000 — Loss: 2.6288\n",
      "Epoch 15/100 — Step 5500 — Loss: 2.7240\n",
      "Epoch 15/100 — Step 6000 — Loss: 2.5406\n",
      "Epoch 15/100 — Step 6500 — Loss: 2.7244\n",
      "Epoch 15/100 — Step 7000 — Loss: 2.6099\n",
      "Epoch 15/100 — Step 7500 — Loss: 2.8045\n",
      "Epoch 15/100 — Step 8000 — Loss: 2.5894\n",
      "Epoch 15/100 — Step 8500 — Loss: 2.7214\n",
      "Epoch 15/100 — Step 9000 — Loss: 2.7649\n",
      "Epoch 15/100 — Step 9500 — Loss: 2.6683\n",
      "Epoch 15/100 — Step 10000 — Loss: 2.5302\n",
      "Epoch 15/100 — Step 10500 — Loss: 2.5179\n",
      "Epoch 15/100 — Step 11000 — Loss: 2.8278\n",
      "Epoch 15/100 — avg_loss: 2.6436, accuracy: 24.66%\n",
      "Epoch 16/100 — Step 500 — Loss: 2.6975\n",
      "Epoch 16/100 — Step 1000 — Loss: 2.4169\n",
      "Epoch 16/100 — Step 1500 — Loss: 2.5094\n",
      "Epoch 16/100 — Step 2000 — Loss: 2.7751\n",
      "Epoch 16/100 — Step 2500 — Loss: 2.5568\n",
      "Epoch 16/100 — Step 3000 — Loss: 3.0206\n",
      "Epoch 16/100 — Step 3500 — Loss: 2.5227\n",
      "Epoch 16/100 — Step 4000 — Loss: 2.5084\n",
      "Epoch 16/100 — Step 4500 — Loss: 2.6694\n",
      "Epoch 16/100 — Step 5000 — Loss: 2.6132\n",
      "Epoch 16/100 — Step 5500 — Loss: 2.7159\n",
      "Epoch 16/100 — Step 6000 — Loss: 2.5316\n",
      "Epoch 16/100 — Step 6500 — Loss: 2.7083\n",
      "Epoch 16/100 — Step 7000 — Loss: 2.5982\n",
      "Epoch 16/100 — Step 7500 — Loss: 2.7933\n",
      "Epoch 16/100 — Step 8000 — Loss: 2.5721\n",
      "Epoch 16/100 — Step 8500 — Loss: 2.7050\n",
      "Epoch 16/100 — Step 9000 — Loss: 2.7498\n",
      "Epoch 16/100 — Step 9500 — Loss: 2.6616\n",
      "Epoch 16/100 — Step 10000 — Loss: 2.5110\n",
      "Epoch 16/100 — Step 10500 — Loss: 2.5125\n",
      "Epoch 16/100 — Step 11000 — Loss: 2.8216\n",
      "Epoch 16/100 — avg_loss: 2.6330, accuracy: 24.78%\n",
      "Epoch 17/100 — Step 500 — Loss: 2.6836\n",
      "Epoch 17/100 — Step 1000 — Loss: 2.4082\n",
      "Epoch 17/100 — Step 1500 — Loss: 2.4979\n",
      "Epoch 17/100 — Step 2000 — Loss: 2.7654\n",
      "Epoch 17/100 — Step 2500 — Loss: 2.5483\n",
      "Epoch 17/100 — Step 3000 — Loss: 3.0158\n",
      "Epoch 17/100 — Step 3500 — Loss: 2.5126\n",
      "Epoch 17/100 — Step 4000 — Loss: 2.5042\n",
      "Epoch 17/100 — Step 4500 — Loss: 2.6475\n",
      "Epoch 17/100 — Step 5000 — Loss: 2.5982\n",
      "Epoch 17/100 — Step 5500 — Loss: 2.7080\n",
      "Epoch 17/100 — Step 6000 — Loss: 2.5230\n",
      "Epoch 17/100 — Step 6500 — Loss: 2.6934\n",
      "Epoch 17/100 — Step 7000 — Loss: 2.5877\n",
      "Epoch 17/100 — Step 7500 — Loss: 2.7828\n",
      "Epoch 17/100 — Step 8000 — Loss: 2.5561\n",
      "Epoch 17/100 — Step 8500 — Loss: 2.6906\n",
      "Epoch 17/100 — Step 9000 — Loss: 2.7355\n",
      "Epoch 17/100 — Step 9500 — Loss: 2.6555\n",
      "Epoch 17/100 — Step 10000 — Loss: 2.4939\n",
      "Epoch 17/100 — Step 10500 — Loss: 2.5077\n",
      "Epoch 17/100 — Step 11000 — Loss: 2.8165\n",
      "Epoch 17/100 — avg_loss: 2.6233, accuracy: 24.89%\n",
      "Epoch 18/100 — Step 500 — Loss: 2.6708\n",
      "Epoch 18/100 — Step 1000 — Loss: 2.4008\n",
      "Epoch 18/100 — Step 1500 — Loss: 2.4879\n",
      "Epoch 18/100 — Step 2000 — Loss: 2.7563\n",
      "Epoch 18/100 — Step 2500 — Loss: 2.5403\n",
      "Epoch 18/100 — Step 3000 — Loss: 3.0115\n",
      "Epoch 18/100 — Step 3500 — Loss: 2.5038\n",
      "Epoch 18/100 — Step 4000 — Loss: 2.5000\n",
      "Epoch 18/100 — Step 4500 — Loss: 2.6273\n",
      "Epoch 18/100 — Step 5000 — Loss: 2.5839\n",
      "Epoch 18/100 — Step 5500 — Loss: 2.7005\n",
      "Epoch 18/100 — Step 6000 — Loss: 2.5150\n",
      "Epoch 18/100 — Step 6500 — Loss: 2.6796\n",
      "Epoch 18/100 — Step 7000 — Loss: 2.5783\n",
      "Epoch 18/100 — Step 7500 — Loss: 2.7731\n",
      "Epoch 18/100 — Step 8000 — Loss: 2.5413\n",
      "Epoch 18/100 — Step 8500 — Loss: 2.6777\n",
      "Epoch 18/100 — Step 9000 — Loss: 2.7221\n",
      "Epoch 18/100 — Step 9500 — Loss: 2.6498\n",
      "Epoch 18/100 — Step 10000 — Loss: 2.4784\n",
      "Epoch 18/100 — Step 10500 — Loss: 2.5035\n",
      "Epoch 18/100 — Step 11000 — Loss: 2.8124\n",
      "Epoch 18/100 — avg_loss: 2.6145, accuracy: 25.00%\n",
      "Epoch 19/100 — Step 500 — Loss: 2.6590\n",
      "Epoch 19/100 — Step 1000 — Loss: 2.3945\n",
      "Epoch 19/100 — Step 1500 — Loss: 2.4789\n",
      "Epoch 19/100 — Step 2000 — Loss: 2.7477\n",
      "Epoch 19/100 — Step 2500 — Loss: 2.5326\n",
      "Epoch 19/100 — Step 3000 — Loss: 3.0076\n",
      "Epoch 19/100 — Step 3500 — Loss: 2.4959\n",
      "Epoch 19/100 — Step 4000 — Loss: 2.4959\n",
      "Epoch 19/100 — Step 4500 — Loss: 2.6086\n",
      "Epoch 19/100 — Step 5000 — Loss: 2.5704\n",
      "Epoch 19/100 — Step 5500 — Loss: 2.6934\n",
      "Epoch 19/100 — Step 6000 — Loss: 2.5073\n",
      "Epoch 19/100 — Step 6500 — Loss: 2.6668\n",
      "Epoch 19/100 — Step 7000 — Loss: 2.5699\n",
      "Epoch 19/100 — Step 7500 — Loss: 2.7641\n",
      "Epoch 19/100 — Step 8000 — Loss: 2.5275\n",
      "Epoch 19/100 — Step 8500 — Loss: 2.6662\n",
      "Epoch 19/100 — Step 9000 — Loss: 2.7096\n",
      "Epoch 19/100 — Step 9500 — Loss: 2.6447\n",
      "Epoch 19/100 — Step 10000 — Loss: 2.4644\n",
      "Epoch 19/100 — Step 10500 — Loss: 2.4996\n",
      "Epoch 19/100 — Step 11000 — Loss: 2.8088\n",
      "Epoch 19/100 — avg_loss: 2.6064, accuracy: 25.09%\n",
      "Epoch 20/100 — Step 500 — Loss: 2.6480\n",
      "Epoch 20/100 — Step 1000 — Loss: 2.3891\n",
      "Epoch 20/100 — Step 1500 — Loss: 2.4709\n",
      "Epoch 20/100 — Step 2000 — Loss: 2.7394\n",
      "Epoch 20/100 — Step 2500 — Loss: 2.5251\n",
      "Epoch 20/100 — Step 3000 — Loss: 3.0038\n",
      "Epoch 20/100 — Step 3500 — Loss: 2.4889\n",
      "Epoch 20/100 — Step 4000 — Loss: 2.4918\n",
      "Epoch 20/100 — Step 4500 — Loss: 2.5914\n",
      "Epoch 20/100 — Step 5000 — Loss: 2.5576\n",
      "Epoch 20/100 — Step 5500 — Loss: 2.6868\n",
      "Epoch 20/100 — Step 6000 — Loss: 2.5001\n",
      "Epoch 20/100 — Step 6500 — Loss: 2.6548\n",
      "Epoch 20/100 — Step 7000 — Loss: 2.5623\n",
      "Epoch 20/100 — Step 7500 — Loss: 2.7557\n",
      "Epoch 20/100 — Step 8000 — Loss: 2.5149\n",
      "Epoch 20/100 — Step 8500 — Loss: 2.6559\n",
      "Epoch 20/100 — Step 9000 — Loss: 2.6979\n",
      "Epoch 20/100 — Step 9500 — Loss: 2.6399\n",
      "Epoch 20/100 — Step 10000 — Loss: 2.4517\n",
      "Epoch 20/100 — Step 10500 — Loss: 2.4960\n",
      "Epoch 20/100 — Step 11000 — Loss: 2.8058\n",
      "Epoch 20/100 — avg_loss: 2.5989, accuracy: 25.18%\n",
      "Epoch 21/100 — Step 500 — Loss: 2.6377\n",
      "Epoch 21/100 — Step 1000 — Loss: 2.3844\n",
      "Epoch 21/100 — Step 1500 — Loss: 2.4637\n",
      "Epoch 21/100 — Step 2000 — Loss: 2.7315\n",
      "Epoch 21/100 — Step 2500 — Loss: 2.5179\n",
      "Epoch 21/100 — Step 3000 — Loss: 3.0003\n",
      "Epoch 21/100 — Step 3500 — Loss: 2.4825\n",
      "Epoch 21/100 — Step 4000 — Loss: 2.4879\n",
      "Epoch 21/100 — Step 4500 — Loss: 2.5754\n",
      "Epoch 21/100 — Step 5000 — Loss: 2.5455\n",
      "Epoch 21/100 — Step 5500 — Loss: 2.6808\n",
      "Epoch 21/100 — Step 6000 — Loss: 2.4932\n",
      "Epoch 21/100 — Step 6500 — Loss: 2.6437\n",
      "Epoch 21/100 — Step 7000 — Loss: 2.5555\n",
      "Epoch 21/100 — Step 7500 — Loss: 2.7479\n",
      "Epoch 21/100 — Step 8000 — Loss: 2.5032\n",
      "Epoch 21/100 — Step 8500 — Loss: 2.6466\n",
      "Epoch 21/100 — Step 9000 — Loss: 2.6869\n",
      "Epoch 21/100 — Step 9500 — Loss: 2.6357\n",
      "Epoch 21/100 — Step 10000 — Loss: 2.4402\n",
      "Epoch 21/100 — Step 10500 — Loss: 2.4926\n",
      "Epoch 21/100 — Step 11000 — Loss: 2.8032\n",
      "Epoch 21/100 — avg_loss: 2.5920, accuracy: 25.26%\n",
      "Epoch 22/100 — Step 500 — Loss: 2.6282\n",
      "Epoch 22/100 — Step 1000 — Loss: 2.3803\n",
      "Epoch 22/100 — Step 1500 — Loss: 2.4571\n",
      "Epoch 22/100 — Step 2000 — Loss: 2.7240\n",
      "Epoch 22/100 — Step 2500 — Loss: 2.5109\n",
      "Epoch 22/100 — Step 3000 — Loss: 2.9969\n",
      "Epoch 22/100 — Step 3500 — Loss: 2.4768\n",
      "Epoch 22/100 — Step 4000 — Loss: 2.4842\n",
      "Epoch 22/100 — Step 4500 — Loss: 2.5605\n",
      "Epoch 22/100 — Step 5000 — Loss: 2.5342\n",
      "Epoch 22/100 — Step 5500 — Loss: 2.6752\n",
      "Epoch 22/100 — Step 6000 — Loss: 2.4868\n",
      "Epoch 22/100 — Step 6500 — Loss: 2.6333\n",
      "Epoch 22/100 — Step 7000 — Loss: 2.5492\n",
      "Epoch 22/100 — Step 7500 — Loss: 2.7407\n",
      "Epoch 22/100 — Step 8000 — Loss: 2.4924\n",
      "Epoch 22/100 — Step 8500 — Loss: 2.6381\n",
      "Epoch 22/100 — Step 9000 — Loss: 2.6767\n",
      "Epoch 22/100 — Step 9500 — Loss: 2.6317\n",
      "Epoch 22/100 — Step 10000 — Loss: 2.4296\n",
      "Epoch 22/100 — Step 10500 — Loss: 2.4894\n",
      "Epoch 22/100 — Step 11000 — Loss: 2.8009\n",
      "Epoch 22/100 — avg_loss: 2.5855, accuracy: 25.35%\n",
      "Epoch 23/100 — Step 500 — Loss: 2.6193\n",
      "Epoch 23/100 — Step 1000 — Loss: 2.3768\n",
      "Epoch 23/100 — Step 1500 — Loss: 2.4511\n",
      "Epoch 23/100 — Step 2000 — Loss: 2.7167\n",
      "Epoch 23/100 — Step 2500 — Loss: 2.5042\n",
      "Epoch 23/100 — Step 3000 — Loss: 2.9936\n",
      "Epoch 23/100 — Step 3500 — Loss: 2.4715\n",
      "Epoch 23/100 — Step 4000 — Loss: 2.4805\n",
      "Epoch 23/100 — Step 4500 — Loss: 2.5466\n",
      "Epoch 23/100 — Step 5000 — Loss: 2.5237\n",
      "Epoch 23/100 — Step 5500 — Loss: 2.6702\n",
      "Epoch 23/100 — Step 6000 — Loss: 2.4807\n",
      "Epoch 23/100 — Step 6500 — Loss: 2.6236\n",
      "Epoch 23/100 — Step 7000 — Loss: 2.5436\n",
      "Epoch 23/100 — Step 7500 — Loss: 2.7340\n",
      "Epoch 23/100 — Step 8000 — Loss: 2.4825\n",
      "Epoch 23/100 — Step 8500 — Loss: 2.6304\n",
      "Epoch 23/100 — Step 9000 — Loss: 2.6671\n",
      "Epoch 23/100 — Step 9500 — Loss: 2.6282\n",
      "Epoch 23/100 — Step 10000 — Loss: 2.4199\n",
      "Epoch 23/100 — Step 10500 — Loss: 2.4863\n",
      "Epoch 23/100 — Step 11000 — Loss: 2.7987\n",
      "Epoch 23/100 — avg_loss: 2.5795, accuracy: 25.43%\n",
      "Epoch 24/100 — Step 500 — Loss: 2.6110\n",
      "Epoch 24/100 — Step 1000 — Loss: 2.3737\n",
      "Epoch 24/100 — Step 1500 — Loss: 2.4456\n",
      "Epoch 24/100 — Step 2000 — Loss: 2.7098\n",
      "Epoch 24/100 — Step 2500 — Loss: 2.4976\n",
      "Epoch 24/100 — Step 3000 — Loss: 2.9905\n",
      "Epoch 24/100 — Step 3500 — Loss: 2.4666\n",
      "Epoch 24/100 — Step 4000 — Loss: 2.4771\n",
      "Epoch 24/100 — Step 4500 — Loss: 2.5335\n",
      "Epoch 24/100 — Step 5000 — Loss: 2.5139\n",
      "Epoch 24/100 — Step 5500 — Loss: 2.6657\n",
      "Epoch 24/100 — Step 6000 — Loss: 2.4750\n",
      "Epoch 24/100 — Step 6500 — Loss: 2.6146\n",
      "Epoch 24/100 — Step 7000 — Loss: 2.5384\n",
      "Epoch 24/100 — Step 7500 — Loss: 2.7278\n",
      "Epoch 24/100 — Step 8000 — Loss: 2.4733\n",
      "Epoch 24/100 — Step 8500 — Loss: 2.6233\n",
      "Epoch 24/100 — Step 9000 — Loss: 2.6581\n",
      "Epoch 24/100 — Step 9500 — Loss: 2.6249\n",
      "Epoch 24/100 — Step 10000 — Loss: 2.4111\n",
      "Epoch 24/100 — Step 10500 — Loss: 2.4834\n",
      "Epoch 24/100 — Step 11000 — Loss: 2.7967\n",
      "Epoch 24/100 — avg_loss: 2.5739, accuracy: 25.50%\n",
      "Epoch 25/100 — Step 500 — Loss: 2.6033\n",
      "Epoch 25/100 — Step 1000 — Loss: 2.3711\n",
      "Epoch 25/100 — Step 1500 — Loss: 2.4405\n",
      "Epoch 25/100 — Step 2000 — Loss: 2.7031\n",
      "Epoch 25/100 — Step 2500 — Loss: 2.4912\n",
      "Epoch 25/100 — Step 3000 — Loss: 2.9875\n",
      "Epoch 25/100 — Step 3500 — Loss: 2.4620\n",
      "Epoch 25/100 — Step 4000 — Loss: 2.4738\n",
      "Epoch 25/100 — Step 4500 — Loss: 2.5213\n",
      "Epoch 25/100 — Step 5000 — Loss: 2.5048\n",
      "Epoch 25/100 — Step 5500 — Loss: 2.6615\n",
      "Epoch 25/100 — Step 6000 — Loss: 2.4698\n",
      "Epoch 25/100 — Step 6500 — Loss: 2.6061\n",
      "Epoch 25/100 — Step 7000 — Loss: 2.5337\n",
      "Epoch 25/100 — Step 7500 — Loss: 2.7219\n",
      "Epoch 25/100 — Step 8000 — Loss: 2.4648\n",
      "Epoch 25/100 — Step 8500 — Loss: 2.6167\n",
      "Epoch 25/100 — Step 9000 — Loss: 2.6497\n",
      "Epoch 25/100 — Step 9500 — Loss: 2.6219\n",
      "Epoch 25/100 — Step 10000 — Loss: 2.4029\n",
      "Epoch 25/100 — Step 10500 — Loss: 2.4807\n",
      "Epoch 25/100 — Step 11000 — Loss: 2.7948\n",
      "Epoch 25/100 — avg_loss: 2.5686, accuracy: 25.56%\n",
      "Epoch 26/100 — Step 500 — Loss: 2.5961\n",
      "Epoch 26/100 — Step 1000 — Loss: 2.3688\n",
      "Epoch 26/100 — Step 1500 — Loss: 2.4358\n",
      "Epoch 26/100 — Step 2000 — Loss: 2.6968\n",
      "Epoch 26/100 — Step 2500 — Loss: 2.4851\n",
      "Epoch 26/100 — Step 3000 — Loss: 2.9846\n",
      "Epoch 26/100 — Step 3500 — Loss: 2.4578\n",
      "Epoch 26/100 — Step 4000 — Loss: 2.4707\n",
      "Epoch 26/100 — Step 4500 — Loss: 2.5098\n",
      "Epoch 26/100 — Step 5000 — Loss: 2.4964\n",
      "Epoch 26/100 — Step 5500 — Loss: 2.6578\n",
      "Epoch 26/100 — Step 6000 — Loss: 2.4648\n",
      "Epoch 26/100 — Step 6500 — Loss: 2.5981\n",
      "Epoch 26/100 — Step 7000 — Loss: 2.5293\n",
      "Epoch 26/100 — Step 7500 — Loss: 2.7165\n",
      "Epoch 26/100 — Step 8000 — Loss: 2.4569\n",
      "Epoch 26/100 — Step 8500 — Loss: 2.6106\n",
      "Epoch 26/100 — Step 9000 — Loss: 2.6417\n",
      "Epoch 26/100 — Step 9500 — Loss: 2.6191\n",
      "Epoch 26/100 — Step 10000 — Loss: 2.3954\n",
      "Epoch 26/100 — Step 10500 — Loss: 2.4780\n",
      "Epoch 26/100 — Step 11000 — Loss: 2.7930\n",
      "Epoch 26/100 — avg_loss: 2.5636, accuracy: 25.62%\n",
      "Epoch 27/100 — Step 500 — Loss: 2.5893\n",
      "Epoch 27/100 — Step 1000 — Loss: 2.3668\n",
      "Epoch 27/100 — Step 1500 — Loss: 2.4314\n",
      "Epoch 27/100 — Step 2000 — Loss: 2.6908\n",
      "Epoch 27/100 — Step 2500 — Loss: 2.4791\n",
      "Epoch 27/100 — Step 3000 — Loss: 2.9819\n",
      "Epoch 27/100 — Step 3500 — Loss: 2.4539\n",
      "Epoch 27/100 — Step 4000 — Loss: 2.4678\n",
      "Epoch 27/100 — Step 4500 — Loss: 2.4990\n",
      "Epoch 27/100 — Step 5000 — Loss: 2.4886\n",
      "Epoch 27/100 — Step 5500 — Loss: 2.6544\n",
      "Epoch 27/100 — Step 6000 — Loss: 2.4602\n",
      "Epoch 27/100 — Step 6500 — Loss: 2.5906\n",
      "Epoch 27/100 — Step 7000 — Loss: 2.5254\n",
      "Epoch 27/100 — Step 7500 — Loss: 2.7114\n",
      "Epoch 27/100 — Step 8000 — Loss: 2.4496\n",
      "Epoch 27/100 — Step 8500 — Loss: 2.6050\n",
      "Epoch 27/100 — Step 9000 — Loss: 2.6342\n",
      "Epoch 27/100 — Step 9500 — Loss: 2.6165\n",
      "Epoch 27/100 — Step 10000 — Loss: 2.3884\n",
      "Epoch 27/100 — Step 10500 — Loss: 2.4755\n",
      "Epoch 27/100 — Step 11000 — Loss: 2.7913\n",
      "Epoch 27/100 — avg_loss: 2.5590, accuracy: 25.67%\n",
      "Epoch 28/100 — Step 500 — Loss: 2.5831\n",
      "Epoch 28/100 — Step 1000 — Loss: 2.3651\n",
      "Epoch 28/100 — Step 1500 — Loss: 2.4274\n",
      "Epoch 28/100 — Step 2000 — Loss: 2.6852\n",
      "Epoch 28/100 — Step 2500 — Loss: 2.4733\n",
      "Epoch 28/100 — Step 3000 — Loss: 2.9794\n",
      "Epoch 28/100 — Step 3500 — Loss: 2.4502\n",
      "Epoch 28/100 — Step 4000 — Loss: 2.4651\n",
      "Epoch 28/100 — Step 4500 — Loss: 2.4888\n",
      "Epoch 28/100 — Step 5000 — Loss: 2.4814\n",
      "Epoch 28/100 — Step 5500 — Loss: 2.6513\n",
      "Epoch 28/100 — Step 6000 — Loss: 2.4560\n",
      "Epoch 28/100 — Step 6500 — Loss: 2.5835\n",
      "Epoch 28/100 — Step 7000 — Loss: 2.5218\n",
      "Epoch 28/100 — Step 7500 — Loss: 2.7066\n",
      "Epoch 28/100 — Step 8000 — Loss: 2.4428\n",
      "Epoch 28/100 — Step 8500 — Loss: 2.5998\n",
      "Epoch 28/100 — Step 9000 — Loss: 2.6271\n",
      "Epoch 28/100 — Step 9500 — Loss: 2.6140\n",
      "Epoch 28/100 — Step 10000 — Loss: 2.3820\n",
      "Epoch 28/100 — Step 10500 — Loss: 2.4730\n",
      "Epoch 28/100 — Step 11000 — Loss: 2.7896\n",
      "Epoch 28/100 — avg_loss: 2.5546, accuracy: 25.72%\n",
      "Epoch 29/100 — Step 500 — Loss: 2.5772\n",
      "Epoch 29/100 — Step 1000 — Loss: 2.3637\n",
      "Epoch 29/100 — Step 1500 — Loss: 2.4236\n",
      "Epoch 29/100 — Step 2000 — Loss: 2.6798\n",
      "Epoch 29/100 — Step 2500 — Loss: 2.4678\n",
      "Epoch 29/100 — Step 3000 — Loss: 2.9771\n",
      "Epoch 29/100 — Step 3500 — Loss: 2.4468\n",
      "Epoch 29/100 — Step 4000 — Loss: 2.4625\n",
      "Epoch 29/100 — Step 4500 — Loss: 2.4791\n",
      "Epoch 29/100 — Step 5000 — Loss: 2.4748\n",
      "Epoch 29/100 — Step 5500 — Loss: 2.6485\n",
      "Epoch 29/100 — Step 6000 — Loss: 2.4520\n",
      "Epoch 29/100 — Step 6500 — Loss: 2.5769\n",
      "Epoch 29/100 — Step 7000 — Loss: 2.5184\n",
      "Epoch 29/100 — Step 7500 — Loss: 2.7021\n",
      "Epoch 29/100 — Step 8000 — Loss: 2.4364\n",
      "Epoch 29/100 — Step 8500 — Loss: 2.5950\n",
      "Epoch 29/100 — Step 9000 — Loss: 2.6203\n",
      "Epoch 29/100 — Step 9500 — Loss: 2.6117\n",
      "Epoch 29/100 — Step 10000 — Loss: 2.3760\n",
      "Epoch 29/100 — Step 10500 — Loss: 2.4707\n",
      "Epoch 29/100 — Step 11000 — Loss: 2.7879\n",
      "Epoch 29/100 — avg_loss: 2.5504, accuracy: 25.78%\n",
      "Epoch 30/100 — Step 500 — Loss: 2.5716\n",
      "Epoch 30/100 — Step 1000 — Loss: 2.3625\n",
      "Epoch 30/100 — Step 1500 — Loss: 2.4201\n",
      "Epoch 30/100 — Step 2000 — Loss: 2.6748\n",
      "Epoch 30/100 — Step 2500 — Loss: 2.4624\n",
      "Epoch 30/100 — Step 3000 — Loss: 2.9750\n",
      "Epoch 30/100 — Step 3500 — Loss: 2.4435\n",
      "Epoch 30/100 — Step 4000 — Loss: 2.4600\n",
      "Epoch 30/100 — Step 4500 — Loss: 2.4699\n",
      "Epoch 30/100 — Step 5000 — Loss: 2.4687\n",
      "Epoch 30/100 — Step 5500 — Loss: 2.6460\n",
      "Epoch 30/100 — Step 6000 — Loss: 2.4484\n",
      "Epoch 30/100 — Step 6500 — Loss: 2.5707\n",
      "Epoch 30/100 — Step 7000 — Loss: 2.5154\n",
      "Epoch 30/100 — Step 7500 — Loss: 2.6979\n",
      "Epoch 30/100 — Step 8000 — Loss: 2.4304\n",
      "Epoch 30/100 — Step 8500 — Loss: 2.5905\n",
      "Epoch 30/100 — Step 9000 — Loss: 2.6139\n",
      "Epoch 30/100 — Step 9500 — Loss: 2.6095\n",
      "Epoch 30/100 — Step 10000 — Loss: 2.3704\n",
      "Epoch 30/100 — Step 10500 — Loss: 2.4684\n",
      "Epoch 30/100 — Step 11000 — Loss: 2.7862\n",
      "Epoch 30/100 — avg_loss: 2.5465, accuracy: 25.83%\n",
      "Epoch 31/100 — Step 500 — Loss: 2.5665\n",
      "Epoch 31/100 — Step 1000 — Loss: 2.3616\n",
      "Epoch 31/100 — Step 1500 — Loss: 2.4168\n",
      "Epoch 31/100 — Step 2000 — Loss: 2.6701\n",
      "Epoch 31/100 — Step 2500 — Loss: 2.4573\n",
      "Epoch 31/100 — Step 3000 — Loss: 2.9731\n",
      "Epoch 31/100 — Step 3500 — Loss: 2.4405\n",
      "Epoch 31/100 — Step 4000 — Loss: 2.4577\n",
      "Epoch 31/100 — Step 4500 — Loss: 2.4612\n",
      "Epoch 31/100 — Step 5000 — Loss: 2.4631\n",
      "Epoch 31/100 — Step 5500 — Loss: 2.6437\n",
      "Epoch 31/100 — Step 6000 — Loss: 2.4450\n",
      "Epoch 31/100 — Step 6500 — Loss: 2.5648\n",
      "Epoch 31/100 — Step 7000 — Loss: 2.5126\n",
      "Epoch 31/100 — Step 7500 — Loss: 2.6938\n",
      "Epoch 31/100 — Step 8000 — Loss: 2.4248\n",
      "Epoch 31/100 — Step 8500 — Loss: 2.5864\n",
      "Epoch 31/100 — Step 9000 — Loss: 2.6078\n",
      "Epoch 31/100 — Step 9500 — Loss: 2.6075\n",
      "Epoch 31/100 — Step 10000 — Loss: 2.3652\n",
      "Epoch 31/100 — Step 10500 — Loss: 2.4663\n",
      "Epoch 31/100 — Step 11000 — Loss: 2.7846\n",
      "Epoch 31/100 — avg_loss: 2.5427, accuracy: 25.87%\n",
      "Epoch 32/100 — Step 500 — Loss: 2.5616\n",
      "Epoch 32/100 — Step 1000 — Loss: 2.3608\n",
      "Epoch 32/100 — Step 1500 — Loss: 2.4137\n",
      "Epoch 32/100 — Step 2000 — Loss: 2.6657\n",
      "Epoch 32/100 — Step 2500 — Loss: 2.4524\n",
      "Epoch 32/100 — Step 3000 — Loss: 2.9714\n",
      "Epoch 32/100 — Step 3500 — Loss: 2.4376\n",
      "Epoch 32/100 — Step 4000 — Loss: 2.4555\n",
      "Epoch 32/100 — Step 4500 — Loss: 2.4530\n",
      "Epoch 32/100 — Step 5000 — Loss: 2.4579\n",
      "Epoch 32/100 — Step 5500 — Loss: 2.6416\n",
      "Epoch 32/100 — Step 6000 — Loss: 2.4418\n",
      "Epoch 32/100 — Step 6500 — Loss: 2.5592\n",
      "Epoch 32/100 — Step 7000 — Loss: 2.5101\n",
      "Epoch 32/100 — Step 7500 — Loss: 2.6900\n",
      "Epoch 32/100 — Step 8000 — Loss: 2.4195\n",
      "Epoch 32/100 — Step 8500 — Loss: 2.5825\n",
      "Epoch 32/100 — Step 9000 — Loss: 2.6019\n",
      "Epoch 32/100 — Step 9500 — Loss: 2.6055\n",
      "Epoch 32/100 — Step 10000 — Loss: 2.3603\n",
      "Epoch 32/100 — Step 10500 — Loss: 2.4643\n",
      "Epoch 32/100 — Step 11000 — Loss: 2.7830\n",
      "Epoch 32/100 — avg_loss: 2.5392, accuracy: 25.92%\n",
      "Epoch 33/100 — Step 500 — Loss: 2.5570\n",
      "Epoch 33/100 — Step 1000 — Loss: 2.3602\n",
      "Epoch 33/100 — Step 1500 — Loss: 2.4109\n",
      "Epoch 33/100 — Step 2000 — Loss: 2.6616\n",
      "Epoch 33/100 — Step 2500 — Loss: 2.4477\n",
      "Epoch 33/100 — Step 3000 — Loss: 2.9699\n",
      "Epoch 33/100 — Step 3500 — Loss: 2.4348\n",
      "Epoch 33/100 — Step 4000 — Loss: 2.4535\n",
      "Epoch 33/100 — Step 4500 — Loss: 2.4451\n",
      "Epoch 33/100 — Step 5000 — Loss: 2.4531\n",
      "Epoch 33/100 — Step 5500 — Loss: 2.6396\n",
      "Epoch 33/100 — Step 6000 — Loss: 2.4389\n",
      "Epoch 33/100 — Step 6500 — Loss: 2.5539\n",
      "Epoch 33/100 — Step 7000 — Loss: 2.5078\n",
      "Epoch 33/100 — Step 7500 — Loss: 2.6863\n",
      "Epoch 33/100 — Step 8000 — Loss: 2.4145\n",
      "Epoch 33/100 — Step 8500 — Loss: 2.5788\n",
      "Epoch 33/100 — Step 9000 — Loss: 2.5964\n",
      "Epoch 33/100 — Step 9500 — Loss: 2.6036\n",
      "Epoch 33/100 — Step 10000 — Loss: 2.3557\n",
      "Epoch 33/100 — Step 10500 — Loss: 2.4623\n",
      "Epoch 33/100 — Step 11000 — Loss: 2.7814\n",
      "Epoch 33/100 — avg_loss: 2.5358, accuracy: 25.95%\n",
      "Epoch 34/100 — Step 500 — Loss: 2.5526\n",
      "Epoch 34/100 — Step 1000 — Loss: 2.3598\n",
      "Epoch 34/100 — Step 1500 — Loss: 2.4082\n",
      "Epoch 34/100 — Step 2000 — Loss: 2.6578\n",
      "Epoch 34/100 — Step 2500 — Loss: 2.4432\n",
      "Epoch 34/100 — Step 3000 — Loss: 2.9686\n",
      "Epoch 34/100 — Step 3500 — Loss: 2.4322\n",
      "Epoch 34/100 — Step 4000 — Loss: 2.4515\n",
      "Epoch 34/100 — Step 4500 — Loss: 2.4376\n",
      "Epoch 34/100 — Step 5000 — Loss: 2.4487\n",
      "Epoch 34/100 — Step 5500 — Loss: 2.6379\n",
      "Epoch 34/100 — Step 6000 — Loss: 2.4362\n",
      "Epoch 34/100 — Step 6500 — Loss: 2.5490\n",
      "Epoch 34/100 — Step 7000 — Loss: 2.5057\n",
      "Epoch 34/100 — Step 7500 — Loss: 2.6829\n",
      "Epoch 34/100 — Step 8000 — Loss: 2.4097\n",
      "Epoch 34/100 — Step 8500 — Loss: 2.5755\n",
      "Epoch 34/100 — Step 9000 — Loss: 2.5910\n",
      "Epoch 34/100 — Step 9500 — Loss: 2.6018\n",
      "Epoch 34/100 — Step 10000 — Loss: 2.3514\n",
      "Epoch 34/100 — Step 10500 — Loss: 2.4605\n",
      "Epoch 34/100 — Step 11000 — Loss: 2.7798\n",
      "Epoch 34/100 — avg_loss: 2.5326, accuracy: 25.99%\n",
      "Epoch 35/100 — Step 500 — Loss: 2.5485\n",
      "Epoch 35/100 — Step 1000 — Loss: 2.3596\n",
      "Epoch 35/100 — Step 1500 — Loss: 2.4058\n",
      "Epoch 35/100 — Step 2000 — Loss: 2.6543\n",
      "Epoch 35/100 — Step 2500 — Loss: 2.4388\n",
      "Epoch 35/100 — Step 3000 — Loss: 2.9675\n",
      "Epoch 35/100 — Step 3500 — Loss: 2.4298\n",
      "Epoch 35/100 — Step 4000 — Loss: 2.4496\n",
      "Epoch 35/100 — Step 4500 — Loss: 2.4304\n",
      "Epoch 35/100 — Step 5000 — Loss: 2.4446\n",
      "Epoch 35/100 — Step 5500 — Loss: 2.6363\n",
      "Epoch 35/100 — Step 6000 — Loss: 2.4337\n",
      "Epoch 35/100 — Step 6500 — Loss: 2.5443\n",
      "Epoch 35/100 — Step 7000 — Loss: 2.5037\n",
      "Epoch 35/100 — Step 7500 — Loss: 2.6795\n",
      "Epoch 35/100 — Step 8000 — Loss: 2.4052\n",
      "Epoch 35/100 — Step 8500 — Loss: 2.5723\n",
      "Epoch 35/100 — Step 9000 — Loss: 2.5859\n",
      "Epoch 35/100 — Step 9500 — Loss: 2.6000\n",
      "Epoch 35/100 — Step 10000 — Loss: 2.3473\n",
      "Epoch 35/100 — Step 10500 — Loss: 2.4587\n",
      "Epoch 35/100 — Step 11000 — Loss: 2.7782\n",
      "Epoch 35/100 — avg_loss: 2.5295, accuracy: 26.03%\n",
      "Epoch 36/100 — Step 500 — Loss: 2.5446\n",
      "Epoch 36/100 — Step 1000 — Loss: 2.3595\n",
      "Epoch 36/100 — Step 1500 — Loss: 2.4034\n",
      "Epoch 36/100 — Step 2000 — Loss: 2.6510\n",
      "Epoch 36/100 — Step 2500 — Loss: 2.4347\n",
      "Epoch 36/100 — Step 3000 — Loss: 2.9665\n",
      "Epoch 36/100 — Step 3500 — Loss: 2.4274\n",
      "Epoch 36/100 — Step 4000 — Loss: 2.4478\n",
      "Epoch 36/100 — Step 4500 — Loss: 2.4236\n",
      "Epoch 36/100 — Step 5000 — Loss: 2.4408\n",
      "Epoch 36/100 — Step 5500 — Loss: 2.6348\n",
      "Epoch 36/100 — Step 6000 — Loss: 2.4314\n",
      "Epoch 36/100 — Step 6500 — Loss: 2.5398\n",
      "Epoch 36/100 — Step 7000 — Loss: 2.5019\n",
      "Epoch 36/100 — Step 7500 — Loss: 2.6763\n",
      "Epoch 36/100 — Step 8000 — Loss: 2.4009\n",
      "Epoch 36/100 — Step 8500 — Loss: 2.5694\n",
      "Epoch 36/100 — Step 9000 — Loss: 2.5809\n",
      "Epoch 36/100 — Step 9500 — Loss: 2.5983\n",
      "Epoch 36/100 — Step 10000 — Loss: 2.3435\n",
      "Epoch 36/100 — Step 10500 — Loss: 2.4570\n",
      "Epoch 36/100 — Step 11000 — Loss: 2.7766\n",
      "Epoch 36/100 — avg_loss: 2.5266, accuracy: 26.06%\n",
      "Epoch 37/100 — Step 500 — Loss: 2.5409\n",
      "Epoch 37/100 — Step 1000 — Loss: 2.3595\n",
      "Epoch 37/100 — Step 1500 — Loss: 2.4013\n",
      "Epoch 37/100 — Step 2000 — Loss: 2.6479\n",
      "Epoch 37/100 — Step 2500 — Loss: 2.4307\n",
      "Epoch 37/100 — Step 3000 — Loss: 2.9658\n",
      "Epoch 37/100 — Step 3500 — Loss: 2.4252\n",
      "Epoch 37/100 — Step 4000 — Loss: 2.4461\n",
      "Epoch 37/100 — Step 4500 — Loss: 2.4170\n",
      "Epoch 37/100 — Step 5000 — Loss: 2.4373\n",
      "Epoch 37/100 — Step 5500 — Loss: 2.6335\n",
      "Epoch 37/100 — Step 6000 — Loss: 2.4292\n",
      "Epoch 37/100 — Step 6500 — Loss: 2.5356\n",
      "Epoch 37/100 — Step 7000 — Loss: 2.5003\n",
      "Epoch 37/100 — Step 7500 — Loss: 2.6732\n",
      "Epoch 37/100 — Step 8000 — Loss: 2.3968\n",
      "Epoch 37/100 — Step 8500 — Loss: 2.5667\n",
      "Epoch 37/100 — Step 9000 — Loss: 2.5762\n",
      "Epoch 37/100 — Step 9500 — Loss: 2.5966\n",
      "Epoch 37/100 — Step 10000 — Loss: 2.3398\n",
      "Epoch 37/100 — Step 10500 — Loss: 2.4554\n",
      "Epoch 37/100 — Step 11000 — Loss: 2.7750\n",
      "Epoch 37/100 — avg_loss: 2.5238, accuracy: 26.10%\n",
      "Epoch 38/100 — Step 500 — Loss: 2.5373\n",
      "Epoch 38/100 — Step 1000 — Loss: 2.3596\n",
      "Epoch 38/100 — Step 1500 — Loss: 2.3993\n",
      "Epoch 38/100 — Step 2000 — Loss: 2.6450\n",
      "Epoch 38/100 — Step 2500 — Loss: 2.4269\n",
      "Epoch 38/100 — Step 3000 — Loss: 2.9651\n",
      "Epoch 38/100 — Step 3500 — Loss: 2.4230\n",
      "Epoch 38/100 — Step 4000 — Loss: 2.4445\n",
      "Epoch 38/100 — Step 4500 — Loss: 2.4108\n",
      "Epoch 38/100 — Step 5000 — Loss: 2.4340\n",
      "Epoch 38/100 — Step 5500 — Loss: 2.6323\n",
      "Epoch 38/100 — Step 6000 — Loss: 2.4272\n",
      "Epoch 38/100 — Step 6500 — Loss: 2.5316\n",
      "Epoch 38/100 — Step 7000 — Loss: 2.4987\n",
      "Epoch 38/100 — Step 7500 — Loss: 2.6702\n",
      "Epoch 38/100 — Step 8000 — Loss: 2.3929\n",
      "Epoch 38/100 — Step 8500 — Loss: 2.5641\n",
      "Epoch 38/100 — Step 9000 — Loss: 2.5716\n",
      "Epoch 38/100 — Step 9500 — Loss: 2.5950\n",
      "Epoch 38/100 — Step 10000 — Loss: 2.3364\n",
      "Epoch 38/100 — Step 10500 — Loss: 2.4539\n",
      "Epoch 38/100 — Step 11000 — Loss: 2.7735\n",
      "Epoch 38/100 — avg_loss: 2.5211, accuracy: 26.13%\n",
      "Epoch 39/100 — Step 500 — Loss: 2.5339\n",
      "Epoch 39/100 — Step 1000 — Loss: 2.3599\n",
      "Epoch 39/100 — Step 1500 — Loss: 2.3974\n",
      "Epoch 39/100 — Step 2000 — Loss: 2.6424\n",
      "Epoch 39/100 — Step 2500 — Loss: 2.4233\n",
      "Epoch 39/100 — Step 3000 — Loss: 2.9646\n",
      "Epoch 39/100 — Step 3500 — Loss: 2.4210\n",
      "Epoch 39/100 — Step 4000 — Loss: 2.4430\n",
      "Epoch 39/100 — Step 4500 — Loss: 2.4048\n",
      "Epoch 39/100 — Step 5000 — Loss: 2.4309\n",
      "Epoch 39/100 — Step 5500 — Loss: 2.6312\n",
      "Epoch 39/100 — Step 6000 — Loss: 2.4254\n",
      "Epoch 39/100 — Step 6500 — Loss: 2.5278\n",
      "Epoch 39/100 — Step 7000 — Loss: 2.4973\n",
      "Epoch 39/100 — Step 7500 — Loss: 2.6673\n",
      "Epoch 39/100 — Step 8000 — Loss: 2.3892\n",
      "Epoch 39/100 — Step 8500 — Loss: 2.5618\n",
      "Epoch 39/100 — Step 9000 — Loss: 2.5672\n",
      "Epoch 39/100 — Step 9500 — Loss: 2.5934\n",
      "Epoch 39/100 — Step 10000 — Loss: 2.3331\n",
      "Epoch 39/100 — Step 10500 — Loss: 2.4525\n",
      "Epoch 39/100 — Step 11000 — Loss: 2.7720\n",
      "Epoch 39/100 — avg_loss: 2.5185, accuracy: 26.16%\n",
      "Epoch 40/100 — Step 500 — Loss: 2.5306\n",
      "Epoch 40/100 — Step 1000 — Loss: 2.3602\n",
      "Epoch 40/100 — Step 1500 — Loss: 2.3957\n",
      "Epoch 40/100 — Step 2000 — Loss: 2.6399\n",
      "Epoch 40/100 — Step 2500 — Loss: 2.4198\n",
      "Epoch 40/100 — Step 3000 — Loss: 2.9642\n",
      "Epoch 40/100 — Step 3500 — Loss: 2.4190\n",
      "Epoch 40/100 — Step 4000 — Loss: 2.4415\n",
      "Epoch 40/100 — Step 4500 — Loss: 2.3990\n",
      "Epoch 40/100 — Step 5000 — Loss: 2.4281\n",
      "Epoch 40/100 — Step 5500 — Loss: 2.6303\n",
      "Epoch 40/100 — Step 6000 — Loss: 2.4237\n",
      "Epoch 40/100 — Step 6500 — Loss: 2.5243\n",
      "Epoch 40/100 — Step 7000 — Loss: 2.4960\n",
      "Epoch 40/100 — Step 7500 — Loss: 2.6645\n",
      "Epoch 40/100 — Step 8000 — Loss: 2.3856\n",
      "Epoch 40/100 — Step 8500 — Loss: 2.5595\n",
      "Epoch 40/100 — Step 9000 — Loss: 2.5629\n",
      "Epoch 40/100 — Step 9500 — Loss: 2.5919\n",
      "Epoch 40/100 — Step 10000 — Loss: 2.3299\n",
      "Epoch 40/100 — Step 10500 — Loss: 2.4511\n",
      "Epoch 40/100 — Step 11000 — Loss: 2.7704\n",
      "Epoch 40/100 — avg_loss: 2.5161, accuracy: 26.20%\n",
      "Epoch 41/100 — Step 500 — Loss: 2.5274\n",
      "Epoch 41/100 — Step 1000 — Loss: 2.3606\n",
      "Epoch 41/100 — Step 1500 — Loss: 2.3941\n",
      "Epoch 41/100 — Step 2000 — Loss: 2.6376\n",
      "Epoch 41/100 — Step 2500 — Loss: 2.4165\n",
      "Epoch 41/100 — Step 3000 — Loss: 2.9639\n",
      "Epoch 41/100 — Step 3500 — Loss: 2.4172\n",
      "Epoch 41/100 — Step 4000 — Loss: 2.4400\n",
      "Epoch 41/100 — Step 4500 — Loss: 2.3935\n",
      "Epoch 41/100 — Step 5000 — Loss: 2.4254\n",
      "Epoch 41/100 — Step 5500 — Loss: 2.6294\n",
      "Epoch 41/100 — Step 6000 — Loss: 2.4222\n",
      "Epoch 41/100 — Step 6500 — Loss: 2.5209\n",
      "Epoch 41/100 — Step 7000 — Loss: 2.4948\n",
      "Epoch 41/100 — Step 7500 — Loss: 2.6618\n",
      "Epoch 41/100 — Step 8000 — Loss: 2.3822\n",
      "Epoch 41/100 — Step 8500 — Loss: 2.5575\n",
      "Epoch 41/100 — Step 9000 — Loss: 2.5588\n",
      "Epoch 41/100 — Step 9500 — Loss: 2.5904\n",
      "Epoch 41/100 — Step 10000 — Loss: 2.3270\n",
      "Epoch 41/100 — Step 10500 — Loss: 2.4497\n",
      "Epoch 41/100 — Step 11000 — Loss: 2.7689\n",
      "Epoch 41/100 — avg_loss: 2.5137, accuracy: 26.23%\n",
      "Epoch 42/100 — Step 500 — Loss: 2.5244\n",
      "Epoch 42/100 — Step 1000 — Loss: 2.3611\n",
      "Epoch 42/100 — Step 1500 — Loss: 2.3926\n",
      "Epoch 42/100 — Step 2000 — Loss: 2.6354\n",
      "Epoch 42/100 — Step 2500 — Loss: 2.4133\n",
      "Epoch 42/100 — Step 3000 — Loss: 2.9637\n",
      "Epoch 42/100 — Step 3500 — Loss: 2.4153\n",
      "Epoch 42/100 — Step 4000 — Loss: 2.4387\n",
      "Epoch 42/100 — Step 4500 — Loss: 2.3882\n",
      "Epoch 42/100 — Step 5000 — Loss: 2.4229\n",
      "Epoch 42/100 — Step 5500 — Loss: 2.6286\n",
      "Epoch 42/100 — Step 6000 — Loss: 2.4208\n",
      "Epoch 42/100 — Step 6500 — Loss: 2.5176\n",
      "Epoch 42/100 — Step 7000 — Loss: 2.4937\n",
      "Epoch 42/100 — Step 7500 — Loss: 2.6592\n",
      "Epoch 42/100 — Step 8000 — Loss: 2.3790\n",
      "Epoch 42/100 — Step 8500 — Loss: 2.5555\n",
      "Epoch 42/100 — Step 9000 — Loss: 2.5547\n",
      "Epoch 42/100 — Step 9500 — Loss: 2.5890\n",
      "Epoch 42/100 — Step 10000 — Loss: 2.3241\n",
      "Epoch 42/100 — Step 10500 — Loss: 2.4485\n",
      "Epoch 42/100 — Step 11000 — Loss: 2.7674\n",
      "Epoch 42/100 — avg_loss: 2.5114, accuracy: 26.26%\n",
      "Epoch 43/100 — Step 500 — Loss: 2.5214\n",
      "Epoch 43/100 — Step 1000 — Loss: 2.3617\n",
      "Epoch 43/100 — Step 1500 — Loss: 2.3912\n",
      "Epoch 43/100 — Step 2000 — Loss: 2.6334\n",
      "Epoch 43/100 — Step 2500 — Loss: 2.4102\n",
      "Epoch 43/100 — Step 3000 — Loss: 2.9635\n",
      "Epoch 43/100 — Step 3500 — Loss: 2.4136\n",
      "Epoch 43/100 — Step 4000 — Loss: 2.4373\n",
      "Epoch 43/100 — Step 4500 — Loss: 2.3832\n",
      "Epoch 43/100 — Step 5000 — Loss: 2.4205\n",
      "Epoch 43/100 — Step 5500 — Loss: 2.6279\n",
      "Epoch 43/100 — Step 6000 — Loss: 2.4194\n",
      "Epoch 43/100 — Step 6500 — Loss: 2.5146\n",
      "Epoch 43/100 — Step 7000 — Loss: 2.4927\n",
      "Epoch 43/100 — Step 7500 — Loss: 2.6567\n",
      "Epoch 43/100 — Step 8000 — Loss: 2.3758\n",
      "Epoch 43/100 — Step 8500 — Loss: 2.5537\n",
      "Epoch 43/100 — Step 9000 — Loss: 2.5509\n",
      "Epoch 43/100 — Step 9500 — Loss: 2.5876\n",
      "Epoch 43/100 — Step 10000 — Loss: 2.3214\n",
      "Epoch 43/100 — Step 10500 — Loss: 2.4472\n",
      "Epoch 43/100 — Step 11000 — Loss: 2.7660\n",
      "Epoch 43/100 — avg_loss: 2.5093, accuracy: 26.29%\n",
      "Epoch 44/100 — Step 500 — Loss: 2.5185\n",
      "Epoch 44/100 — Step 1000 — Loss: 2.3623\n",
      "Epoch 44/100 — Step 1500 — Loss: 2.3899\n",
      "Epoch 44/100 — Step 2000 — Loss: 2.6315\n",
      "Epoch 44/100 — Step 2500 — Loss: 2.4073\n",
      "Epoch 44/100 — Step 3000 — Loss: 2.9634\n",
      "Epoch 44/100 — Step 3500 — Loss: 2.4119\n",
      "Epoch 44/100 — Step 4000 — Loss: 2.4360\n",
      "Epoch 44/100 — Step 4500 — Loss: 2.3783\n",
      "Epoch 44/100 — Step 5000 — Loss: 2.4183\n",
      "Epoch 44/100 — Step 5500 — Loss: 2.6273\n",
      "Epoch 44/100 — Step 6000 — Loss: 2.4182\n",
      "Epoch 44/100 — Step 6500 — Loss: 2.5116\n",
      "Epoch 44/100 — Step 7000 — Loss: 2.4917\n",
      "Epoch 44/100 — Step 7500 — Loss: 2.6542\n",
      "Epoch 44/100 — Step 8000 — Loss: 2.3728\n",
      "Epoch 44/100 — Step 8500 — Loss: 2.5520\n",
      "Epoch 44/100 — Step 9000 — Loss: 2.5471\n",
      "Epoch 44/100 — Step 9500 — Loss: 2.5862\n",
      "Epoch 44/100 — Step 10000 — Loss: 2.3188\n",
      "Epoch 44/100 — Step 10500 — Loss: 2.4461\n",
      "Epoch 44/100 — Step 11000 — Loss: 2.7645\n",
      "Epoch 44/100 — avg_loss: 2.5072, accuracy: 26.31%\n",
      "Epoch 45/100 — Step 500 — Loss: 2.5157\n",
      "Epoch 45/100 — Step 1000 — Loss: 2.3630\n",
      "Epoch 45/100 — Step 1500 — Loss: 2.3887\n",
      "Epoch 45/100 — Step 2000 — Loss: 2.6297\n",
      "Epoch 45/100 — Step 2500 — Loss: 2.4044\n",
      "Epoch 45/100 — Step 3000 — Loss: 2.9634\n",
      "Epoch 45/100 — Step 3500 — Loss: 2.4103\n",
      "Epoch 45/100 — Step 4000 — Loss: 2.4348\n",
      "Epoch 45/100 — Step 4500 — Loss: 2.3736\n",
      "Epoch 45/100 — Step 5000 — Loss: 2.4162\n",
      "Epoch 45/100 — Step 5500 — Loss: 2.6267\n",
      "Epoch 45/100 — Step 6000 — Loss: 2.4171\n",
      "Epoch 45/100 — Step 6500 — Loss: 2.5089\n",
      "Epoch 45/100 — Step 7000 — Loss: 2.4908\n",
      "Epoch 45/100 — Step 7500 — Loss: 2.6518\n",
      "Epoch 45/100 — Step 8000 — Loss: 2.3699\n",
      "Epoch 45/100 — Step 8500 — Loss: 2.5505\n",
      "Epoch 45/100 — Step 9000 — Loss: 2.5434\n",
      "Epoch 45/100 — Step 9500 — Loss: 2.5849\n",
      "Epoch 45/100 — Step 10000 — Loss: 2.3164\n",
      "Epoch 45/100 — Step 10500 — Loss: 2.4450\n",
      "Epoch 45/100 — Step 11000 — Loss: 2.7631\n",
      "Epoch 45/100 — avg_loss: 2.5051, accuracy: 26.34%\n",
      "Epoch 46/100 — Step 500 — Loss: 2.5130\n",
      "Epoch 46/100 — Step 1000 — Loss: 2.3637\n",
      "Epoch 46/100 — Step 1500 — Loss: 2.3876\n",
      "Epoch 46/100 — Step 2000 — Loss: 2.6280\n",
      "Epoch 46/100 — Step 2500 — Loss: 2.4017\n",
      "Epoch 46/100 — Step 3000 — Loss: 2.9633\n",
      "Epoch 46/100 — Step 3500 — Loss: 2.4088\n",
      "Epoch 46/100 — Step 4000 — Loss: 2.4336\n",
      "Epoch 46/100 — Step 4500 — Loss: 2.3691\n",
      "Epoch 46/100 — Step 5000 — Loss: 2.4142\n",
      "Epoch 46/100 — Step 5500 — Loss: 2.6263\n",
      "Epoch 46/100 — Step 6000 — Loss: 2.4161\n",
      "Epoch 46/100 — Step 6500 — Loss: 2.5062\n",
      "Epoch 46/100 — Step 7000 — Loss: 2.4899\n",
      "Epoch 46/100 — Step 7500 — Loss: 2.6494\n",
      "Epoch 46/100 — Step 8000 — Loss: 2.3672\n",
      "Epoch 46/100 — Step 8500 — Loss: 2.5490\n",
      "Epoch 46/100 — Step 9000 — Loss: 2.5398\n",
      "Epoch 46/100 — Step 9500 — Loss: 2.5835\n",
      "Epoch 46/100 — Step 10000 — Loss: 2.3140\n",
      "Epoch 46/100 — Step 10500 — Loss: 2.4439\n",
      "Epoch 46/100 — Step 11000 — Loss: 2.7616\n",
      "Epoch 46/100 — avg_loss: 2.5032, accuracy: 26.36%\n",
      "Epoch 47/100 — Step 500 — Loss: 2.5104\n",
      "Epoch 47/100 — Step 1000 — Loss: 2.3645\n",
      "Epoch 47/100 — Step 1500 — Loss: 2.3865\n",
      "Epoch 47/100 — Step 2000 — Loss: 2.6264\n",
      "Epoch 47/100 — Step 2500 — Loss: 2.3990\n",
      "Epoch 47/100 — Step 3000 — Loss: 2.9633\n",
      "Epoch 47/100 — Step 3500 — Loss: 2.4073\n",
      "Epoch 47/100 — Step 4000 — Loss: 2.4324\n",
      "Epoch 47/100 — Step 4500 — Loss: 2.3647\n",
      "Epoch 47/100 — Step 5000 — Loss: 2.4123\n",
      "Epoch 47/100 — Step 5500 — Loss: 2.6259\n",
      "Epoch 47/100 — Step 6000 — Loss: 2.4151\n",
      "Epoch 47/100 — Step 6500 — Loss: 2.5037\n",
      "Epoch 47/100 — Step 7000 — Loss: 2.4891\n",
      "Epoch 47/100 — Step 7500 — Loss: 2.6472\n",
      "Epoch 47/100 — Step 8000 — Loss: 2.3645\n",
      "Epoch 47/100 — Step 8500 — Loss: 2.5476\n",
      "Epoch 47/100 — Step 9000 — Loss: 2.5364\n",
      "Epoch 47/100 — Step 9500 — Loss: 2.5823\n",
      "Epoch 47/100 — Step 10000 — Loss: 2.3117\n",
      "Epoch 47/100 — Step 10500 — Loss: 2.4429\n",
      "Epoch 47/100 — Step 11000 — Loss: 2.7602\n",
      "Epoch 47/100 — avg_loss: 2.5013, accuracy: 26.38%\n",
      "Epoch 48/100 — Step 500 — Loss: 2.5078\n",
      "Epoch 48/100 — Step 1000 — Loss: 2.3653\n",
      "Epoch 48/100 — Step 1500 — Loss: 2.3855\n",
      "Epoch 48/100 — Step 2000 — Loss: 2.6248\n",
      "Epoch 48/100 — Step 2500 — Loss: 2.3965\n",
      "Epoch 48/100 — Step 3000 — Loss: 2.9633\n",
      "Epoch 48/100 — Step 3500 — Loss: 2.4058\n",
      "Epoch 48/100 — Step 4000 — Loss: 2.4313\n",
      "Epoch 48/100 — Step 4500 — Loss: 2.3606\n",
      "Epoch 48/100 — Step 5000 — Loss: 2.4105\n",
      "Epoch 48/100 — Step 5500 — Loss: 2.6255\n",
      "Epoch 48/100 — Step 6000 — Loss: 2.4143\n",
      "Epoch 48/100 — Step 6500 — Loss: 2.5013\n",
      "Epoch 48/100 — Step 7000 — Loss: 2.4883\n",
      "Epoch 48/100 — Step 7500 — Loss: 2.6449\n",
      "Epoch 48/100 — Step 8000 — Loss: 2.3620\n",
      "Epoch 48/100 — Step 8500 — Loss: 2.5463\n",
      "Epoch 48/100 — Step 9000 — Loss: 2.5330\n",
      "Epoch 48/100 — Step 9500 — Loss: 2.5810\n",
      "Epoch 48/100 — Step 10000 — Loss: 2.3095\n",
      "Epoch 48/100 — Step 10500 — Loss: 2.4419\n",
      "Epoch 48/100 — Step 11000 — Loss: 2.7588\n",
      "Epoch 48/100 — avg_loss: 2.4995, accuracy: 26.41%\n",
      "Epoch 49/100 — Step 500 — Loss: 2.5053\n",
      "Epoch 49/100 — Step 1000 — Loss: 2.3661\n",
      "Epoch 49/100 — Step 1500 — Loss: 2.3846\n",
      "Epoch 49/100 — Step 2000 — Loss: 2.6234\n",
      "Epoch 49/100 — Step 2500 — Loss: 2.3940\n",
      "Epoch 49/100 — Step 3000 — Loss: 2.9634\n",
      "Epoch 49/100 — Step 3500 — Loss: 2.4044\n",
      "Epoch 49/100 — Step 4000 — Loss: 2.4302\n",
      "Epoch 49/100 — Step 4500 — Loss: 2.3565\n",
      "Epoch 49/100 — Step 5000 — Loss: 2.4088\n",
      "Epoch 49/100 — Step 5500 — Loss: 2.6252\n",
      "Epoch 49/100 — Step 6000 — Loss: 2.4135\n",
      "Epoch 49/100 — Step 6500 — Loss: 2.4990\n",
      "Epoch 49/100 — Step 7000 — Loss: 2.4876\n",
      "Epoch 49/100 — Step 7500 — Loss: 2.6428\n",
      "Epoch 49/100 — Step 8000 — Loss: 2.3595\n",
      "Epoch 49/100 — Step 8500 — Loss: 2.5450\n",
      "Epoch 49/100 — Step 9000 — Loss: 2.5297\n",
      "Epoch 49/100 — Step 9500 — Loss: 2.5798\n",
      "Epoch 49/100 — Step 10000 — Loss: 2.3074\n",
      "Epoch 49/100 — Step 10500 — Loss: 2.4409\n",
      "Epoch 49/100 — Step 11000 — Loss: 2.7574\n",
      "Epoch 49/100 — avg_loss: 2.4977, accuracy: 26.42%\n",
      "Epoch 50/100 — Step 500 — Loss: 2.5028\n",
      "Epoch 50/100 — Step 1000 — Loss: 2.3670\n",
      "Epoch 50/100 — Step 1500 — Loss: 2.3837\n",
      "Epoch 50/100 — Step 2000 — Loss: 2.6220\n",
      "Epoch 50/100 — Step 2500 — Loss: 2.3916\n",
      "Epoch 50/100 — Step 3000 — Loss: 2.9634\n",
      "Epoch 50/100 — Step 3500 — Loss: 2.4031\n",
      "Epoch 50/100 — Step 4000 — Loss: 2.4291\n",
      "Epoch 50/100 — Step 4500 — Loss: 2.3526\n",
      "Epoch 50/100 — Step 5000 — Loss: 2.4071\n",
      "Epoch 50/100 — Step 5500 — Loss: 2.6250\n",
      "Epoch 50/100 — Step 6000 — Loss: 2.4127\n",
      "Epoch 50/100 — Step 6500 — Loss: 2.4969\n",
      "Epoch 50/100 — Step 7000 — Loss: 2.4869\n",
      "Epoch 50/100 — Step 7500 — Loss: 2.6406\n",
      "Epoch 50/100 — Step 8000 — Loss: 2.3572\n",
      "Epoch 50/100 — Step 8500 — Loss: 2.5439\n",
      "Epoch 50/100 — Step 9000 — Loss: 2.5264\n",
      "Epoch 50/100 — Step 9500 — Loss: 2.5787\n",
      "Epoch 50/100 — Step 10000 — Loss: 2.3054\n",
      "Epoch 50/100 — Step 10500 — Loss: 2.4400\n",
      "Epoch 50/100 — Step 11000 — Loss: 2.7560\n",
      "Epoch 50/100 — avg_loss: 2.4960, accuracy: 26.44%\n",
      "Epoch 51/100 — Step 500 — Loss: 2.5004\n",
      "Epoch 51/100 — Step 1000 — Loss: 2.3678\n",
      "Epoch 51/100 — Step 1500 — Loss: 2.3829\n",
      "Epoch 51/100 — Step 2000 — Loss: 2.6207\n",
      "Epoch 51/100 — Step 2500 — Loss: 2.3893\n",
      "Epoch 51/100 — Step 3000 — Loss: 2.9634\n",
      "Epoch 51/100 — Step 3500 — Loss: 2.4017\n",
      "Epoch 51/100 — Step 4000 — Loss: 2.4281\n",
      "Epoch 51/100 — Step 4500 — Loss: 2.3489\n",
      "Epoch 51/100 — Step 5000 — Loss: 2.4056\n",
      "Epoch 51/100 — Step 5500 — Loss: 2.6248\n",
      "Epoch 51/100 — Step 6000 — Loss: 2.4121\n",
      "Epoch 51/100 — Step 6500 — Loss: 2.4948\n",
      "Epoch 51/100 — Step 7000 — Loss: 2.4862\n",
      "Epoch 51/100 — Step 7500 — Loss: 2.6386\n",
      "Epoch 51/100 — Step 8000 — Loss: 2.3549\n",
      "Epoch 51/100 — Step 8500 — Loss: 2.5428\n",
      "Epoch 51/100 — Step 9000 — Loss: 2.5233\n",
      "Epoch 51/100 — Step 9500 — Loss: 2.5775\n",
      "Epoch 51/100 — Step 10000 — Loss: 2.3035\n",
      "Epoch 51/100 — Step 10500 — Loss: 2.4391\n",
      "Epoch 51/100 — Step 11000 — Loss: 2.7546\n",
      "Epoch 51/100 — avg_loss: 2.4944, accuracy: 26.46%\n",
      "Epoch 52/100 — Step 500 — Loss: 2.4980\n",
      "Epoch 52/100 — Step 1000 — Loss: 2.3687\n",
      "Epoch 52/100 — Step 1500 — Loss: 2.3821\n",
      "Epoch 52/100 — Step 2000 — Loss: 2.6194\n",
      "Epoch 52/100 — Step 2500 — Loss: 2.3871\n",
      "Epoch 52/100 — Step 3000 — Loss: 2.9634\n",
      "Epoch 52/100 — Step 3500 — Loss: 2.4005\n",
      "Epoch 52/100 — Step 4000 — Loss: 2.4271\n",
      "Epoch 52/100 — Step 4500 — Loss: 2.3453\n",
      "Epoch 52/100 — Step 5000 — Loss: 2.4041\n",
      "Epoch 52/100 — Step 5500 — Loss: 2.6247\n",
      "Epoch 52/100 — Step 6000 — Loss: 2.4115\n",
      "Epoch 52/100 — Step 6500 — Loss: 2.4928\n",
      "Epoch 52/100 — Step 7000 — Loss: 2.4856\n",
      "Epoch 52/100 — Step 7500 — Loss: 2.6366\n",
      "Epoch 52/100 — Step 8000 — Loss: 2.3527\n",
      "Epoch 52/100 — Step 8500 — Loss: 2.5417\n",
      "Epoch 52/100 — Step 9000 — Loss: 2.5202\n",
      "Epoch 52/100 — Step 9500 — Loss: 2.5764\n",
      "Epoch 52/100 — Step 10000 — Loss: 2.3016\n",
      "Epoch 52/100 — Step 10500 — Loss: 2.4383\n",
      "Epoch 52/100 — Step 11000 — Loss: 2.7532\n",
      "Epoch 52/100 — avg_loss: 2.4928, accuracy: 26.48%\n",
      "Epoch 53/100 — Step 500 — Loss: 2.4957\n",
      "Epoch 53/100 — Step 1000 — Loss: 2.3696\n",
      "Epoch 53/100 — Step 1500 — Loss: 2.3814\n",
      "Epoch 53/100 — Step 2000 — Loss: 2.6182\n",
      "Epoch 53/100 — Step 2500 — Loss: 2.3849\n",
      "Epoch 53/100 — Step 3000 — Loss: 2.9634\n",
      "Epoch 53/100 — Step 3500 — Loss: 2.3992\n",
      "Epoch 53/100 — Step 4000 — Loss: 2.4261\n",
      "Epoch 53/100 — Step 4500 — Loss: 2.3418\n",
      "Epoch 53/100 — Step 5000 — Loss: 2.4027\n",
      "Epoch 53/100 — Step 5500 — Loss: 2.6246\n",
      "Epoch 53/100 — Step 6000 — Loss: 2.4109\n",
      "Epoch 53/100 — Step 6500 — Loss: 2.4909\n",
      "Epoch 53/100 — Step 7000 — Loss: 2.4850\n",
      "Epoch 53/100 — Step 7500 — Loss: 2.6346\n",
      "Epoch 53/100 — Step 8000 — Loss: 2.3506\n",
      "Epoch 53/100 — Step 8500 — Loss: 2.5407\n",
      "Epoch 53/100 — Step 9000 — Loss: 2.5172\n",
      "Epoch 53/100 — Step 9500 — Loss: 2.5753\n",
      "Epoch 53/100 — Step 10000 — Loss: 2.2998\n",
      "Epoch 53/100 — Step 10500 — Loss: 2.4375\n",
      "Epoch 53/100 — Step 11000 — Loss: 2.7519\n",
      "Epoch 53/100 — avg_loss: 2.4912, accuracy: 26.50%\n",
      "Epoch 54/100 — Step 500 — Loss: 2.4934\n",
      "Epoch 54/100 — Step 1000 — Loss: 2.3705\n",
      "Epoch 54/100 — Step 1500 — Loss: 2.3807\n",
      "Epoch 54/100 — Step 2000 — Loss: 2.6170\n",
      "Epoch 54/100 — Step 2500 — Loss: 2.3828\n",
      "Epoch 54/100 — Step 3000 — Loss: 2.9633\n",
      "Epoch 54/100 — Step 3500 — Loss: 2.3980\n",
      "Epoch 54/100 — Step 4000 — Loss: 2.4251\n",
      "Epoch 54/100 — Step 4500 — Loss: 2.3384\n",
      "Epoch 54/100 — Step 5000 — Loss: 2.4013\n",
      "Epoch 54/100 — Step 5500 — Loss: 2.6245\n",
      "Epoch 54/100 — Step 6000 — Loss: 2.4104\n",
      "Epoch 54/100 — Step 6500 — Loss: 2.4891\n",
      "Epoch 54/100 — Step 7000 — Loss: 2.4844\n",
      "Epoch 54/100 — Step 7500 — Loss: 2.6327\n",
      "Epoch 54/100 — Step 8000 — Loss: 2.3486\n",
      "Epoch 54/100 — Step 8500 — Loss: 2.5398\n",
      "Epoch 54/100 — Step 9000 — Loss: 2.5143\n",
      "Epoch 54/100 — Step 9500 — Loss: 2.5742\n",
      "Epoch 54/100 — Step 10000 — Loss: 2.2980\n",
      "Epoch 54/100 — Step 10500 — Loss: 2.4367\n",
      "Epoch 54/100 — Step 11000 — Loss: 2.7505\n",
      "Epoch 54/100 — avg_loss: 2.4897, accuracy: 26.52%\n",
      "Epoch 55/100 — Step 500 — Loss: 2.4912\n",
      "Epoch 55/100 — Step 1000 — Loss: 2.3714\n",
      "Epoch 55/100 — Step 1500 — Loss: 2.3800\n",
      "Epoch 55/100 — Step 2000 — Loss: 2.6159\n",
      "Epoch 55/100 — Step 2500 — Loss: 2.3808\n",
      "Epoch 55/100 — Step 3000 — Loss: 2.9633\n",
      "Epoch 55/100 — Step 3500 — Loss: 2.3969\n",
      "Epoch 55/100 — Step 4000 — Loss: 2.4241\n",
      "Epoch 55/100 — Step 4500 — Loss: 2.3351\n",
      "Epoch 55/100 — Step 5000 — Loss: 2.3999\n",
      "Epoch 55/100 — Step 5500 — Loss: 2.6245\n",
      "Epoch 55/100 — Step 6000 — Loss: 2.4100\n",
      "Epoch 55/100 — Step 6500 — Loss: 2.4873\n",
      "Epoch 55/100 — Step 7000 — Loss: 2.4838\n",
      "Epoch 55/100 — Step 7500 — Loss: 2.6308\n",
      "Epoch 55/100 — Step 8000 — Loss: 2.3466\n",
      "Epoch 55/100 — Step 8500 — Loss: 2.5389\n",
      "Epoch 55/100 — Step 9000 — Loss: 2.5114\n",
      "Epoch 55/100 — Step 9500 — Loss: 2.5732\n",
      "Epoch 55/100 — Step 10000 — Loss: 2.2963\n",
      "Epoch 55/100 — Step 10500 — Loss: 2.4359\n",
      "Epoch 55/100 — Step 11000 — Loss: 2.7492\n",
      "Epoch 55/100 — avg_loss: 2.4883, accuracy: 26.54%\n",
      "Epoch 56/100 — Step 500 — Loss: 2.4890\n",
      "Epoch 56/100 — Step 1000 — Loss: 2.3723\n",
      "Epoch 56/100 — Step 1500 — Loss: 2.3794\n",
      "Epoch 56/100 — Step 2000 — Loss: 2.6148\n",
      "Epoch 56/100 — Step 2500 — Loss: 2.3788\n",
      "Epoch 56/100 — Step 3000 — Loss: 2.9632\n",
      "Epoch 56/100 — Step 3500 — Loss: 2.3957\n",
      "Epoch 56/100 — Step 4000 — Loss: 2.4232\n",
      "Epoch 56/100 — Step 4500 — Loss: 2.3320\n",
      "Epoch 56/100 — Step 5000 — Loss: 2.3987\n",
      "Epoch 56/100 — Step 5500 — Loss: 2.6244\n",
      "Epoch 56/100 — Step 6000 — Loss: 2.4095\n",
      "Epoch 56/100 — Step 6500 — Loss: 2.4856\n",
      "Epoch 56/100 — Step 7000 — Loss: 2.4833\n",
      "Epoch 56/100 — Step 7500 — Loss: 2.6290\n",
      "Epoch 56/100 — Step 8000 — Loss: 2.3448\n",
      "Epoch 56/100 — Step 8500 — Loss: 2.5380\n",
      "Epoch 56/100 — Step 9000 — Loss: 2.5086\n",
      "Epoch 56/100 — Step 9500 — Loss: 2.5722\n",
      "Epoch 56/100 — Step 10000 — Loss: 2.2947\n",
      "Epoch 56/100 — Step 10500 — Loss: 2.4352\n",
      "Epoch 56/100 — Step 11000 — Loss: 2.7478\n",
      "Epoch 56/100 — avg_loss: 2.4868, accuracy: 26.55%\n",
      "Epoch 57/100 — Step 500 — Loss: 2.4868\n",
      "Epoch 57/100 — Step 1000 — Loss: 2.3731\n",
      "Epoch 57/100 — Step 1500 — Loss: 2.3788\n",
      "Epoch 57/100 — Step 2000 — Loss: 2.6137\n",
      "Epoch 57/100 — Step 2500 — Loss: 2.3769\n",
      "Epoch 57/100 — Step 3000 — Loss: 2.9630\n",
      "Epoch 57/100 — Step 3500 — Loss: 2.3946\n",
      "Epoch 57/100 — Step 4000 — Loss: 2.4223\n",
      "Epoch 57/100 — Step 4500 — Loss: 2.3289\n",
      "Epoch 57/100 — Step 5000 — Loss: 2.3974\n",
      "Epoch 57/100 — Step 5500 — Loss: 2.6245\n",
      "Epoch 57/100 — Step 6000 — Loss: 2.4092\n",
      "Epoch 57/100 — Step 6500 — Loss: 2.4840\n",
      "Epoch 57/100 — Step 7000 — Loss: 2.4828\n",
      "Epoch 57/100 — Step 7500 — Loss: 2.6272\n",
      "Epoch 57/100 — Step 8000 — Loss: 2.3429\n",
      "Epoch 57/100 — Step 8500 — Loss: 2.5372\n",
      "Epoch 57/100 — Step 9000 — Loss: 2.5058\n",
      "Epoch 57/100 — Step 9500 — Loss: 2.5712\n",
      "Epoch 57/100 — Step 10000 — Loss: 2.2931\n",
      "Epoch 57/100 — Step 10500 — Loss: 2.4345\n",
      "Epoch 57/100 — Step 11000 — Loss: 2.7465\n",
      "Epoch 57/100 — avg_loss: 2.4855, accuracy: 26.57%\n",
      "Epoch 58/100 — Step 500 — Loss: 2.4847\n",
      "Epoch 58/100 — Step 1000 — Loss: 2.3740\n",
      "Epoch 58/100 — Step 1500 — Loss: 2.3782\n",
      "Epoch 58/100 — Step 2000 — Loss: 2.6127\n",
      "Epoch 58/100 — Step 2500 — Loss: 2.3750\n",
      "Epoch 58/100 — Step 3000 — Loss: 2.9629\n",
      "Epoch 58/100 — Step 3500 — Loss: 2.3935\n",
      "Epoch 58/100 — Step 4000 — Loss: 2.4214\n",
      "Epoch 58/100 — Step 4500 — Loss: 2.3259\n",
      "Epoch 58/100 — Step 5000 — Loss: 2.3962\n",
      "Epoch 58/100 — Step 5500 — Loss: 2.6245\n",
      "Epoch 58/100 — Step 6000 — Loss: 2.4088\n",
      "Epoch 58/100 — Step 6500 — Loss: 2.4825\n",
      "Epoch 58/100 — Step 7000 — Loss: 2.4823\n",
      "Epoch 58/100 — Step 7500 — Loss: 2.6254\n",
      "Epoch 58/100 — Step 8000 — Loss: 2.3412\n",
      "Epoch 58/100 — Step 8500 — Loss: 2.5364\n",
      "Epoch 58/100 — Step 9000 — Loss: 2.5031\n",
      "Epoch 58/100 — Step 9500 — Loss: 2.5702\n",
      "Epoch 58/100 — Step 10000 — Loss: 2.2916\n",
      "Epoch 58/100 — Step 10500 — Loss: 2.4339\n",
      "Epoch 58/100 — Step 11000 — Loss: 2.7452\n",
      "Epoch 58/100 — avg_loss: 2.4841, accuracy: 26.59%\n",
      "Epoch 59/100 — Step 500 — Loss: 2.4826\n",
      "Epoch 59/100 — Step 1000 — Loss: 2.3749\n",
      "Epoch 59/100 — Step 1500 — Loss: 2.3777\n",
      "Epoch 59/100 — Step 2000 — Loss: 2.6117\n",
      "Epoch 59/100 — Step 2500 — Loss: 2.3732\n",
      "Epoch 59/100 — Step 3000 — Loss: 2.9627\n",
      "Epoch 59/100 — Step 3500 — Loss: 2.3925\n",
      "Epoch 59/100 — Step 4000 — Loss: 2.4205\n",
      "Epoch 59/100 — Step 4500 — Loss: 2.3231\n",
      "Epoch 59/100 — Step 5000 — Loss: 2.3950\n",
      "Epoch 59/100 — Step 5500 — Loss: 2.6245\n",
      "Epoch 59/100 — Step 6000 — Loss: 2.4085\n",
      "Epoch 59/100 — Step 6500 — Loss: 2.4810\n",
      "Epoch 59/100 — Step 7000 — Loss: 2.4818\n",
      "Epoch 59/100 — Step 7500 — Loss: 2.6237\n",
      "Epoch 59/100 — Step 8000 — Loss: 2.3395\n",
      "Epoch 59/100 — Step 8500 — Loss: 2.5357\n",
      "Epoch 59/100 — Step 9000 — Loss: 2.5005\n",
      "Epoch 59/100 — Step 9500 — Loss: 2.5692\n",
      "Epoch 59/100 — Step 10000 — Loss: 2.2901\n",
      "Epoch 59/100 — Step 10500 — Loss: 2.4332\n",
      "Epoch 59/100 — Step 11000 — Loss: 2.7439\n",
      "Epoch 59/100 — avg_loss: 2.4828, accuracy: 26.61%\n",
      "Epoch 60/100 — Step 500 — Loss: 2.4805\n",
      "Epoch 60/100 — Step 1000 — Loss: 2.3757\n",
      "Epoch 60/100 — Step 1500 — Loss: 2.3772\n",
      "Epoch 60/100 — Step 2000 — Loss: 2.6108\n",
      "Epoch 60/100 — Step 2500 — Loss: 2.3714\n",
      "Epoch 60/100 — Step 3000 — Loss: 2.9625\n",
      "Epoch 60/100 — Step 3500 — Loss: 2.3915\n",
      "Epoch 60/100 — Step 4000 — Loss: 2.4197\n",
      "Epoch 60/100 — Step 4500 — Loss: 2.3203\n",
      "Epoch 60/100 — Step 5000 — Loss: 2.3939\n",
      "Epoch 60/100 — Step 5500 — Loss: 2.6246\n",
      "Epoch 60/100 — Step 6000 — Loss: 2.4083\n",
      "Epoch 60/100 — Step 6500 — Loss: 2.4796\n",
      "Epoch 60/100 — Step 7000 — Loss: 2.4813\n",
      "Epoch 60/100 — Step 7500 — Loss: 2.6220\n",
      "Epoch 60/100 — Step 8000 — Loss: 2.3379\n",
      "Epoch 60/100 — Step 8500 — Loss: 2.5350\n",
      "Epoch 60/100 — Step 9000 — Loss: 2.4979\n",
      "Epoch 60/100 — Step 9500 — Loss: 2.5683\n",
      "Epoch 60/100 — Step 10000 — Loss: 2.2886\n",
      "Epoch 60/100 — Step 10500 — Loss: 2.4326\n",
      "Epoch 60/100 — Step 11000 — Loss: 2.7426\n",
      "Epoch 60/100 — avg_loss: 2.4816, accuracy: 26.62%\n",
      "Epoch 61/100 — Step 500 — Loss: 2.4785\n",
      "Epoch 61/100 — Step 1000 — Loss: 2.3766\n",
      "Epoch 61/100 — Step 1500 — Loss: 2.3767\n",
      "Epoch 61/100 — Step 2000 — Loss: 2.6098\n",
      "Epoch 61/100 — Step 2500 — Loss: 2.3697\n",
      "Epoch 61/100 — Step 3000 — Loss: 2.9623\n",
      "Epoch 61/100 — Step 3500 — Loss: 2.3905\n",
      "Epoch 61/100 — Step 4000 — Loss: 2.4189\n",
      "Epoch 61/100 — Step 4500 — Loss: 2.3176\n",
      "Epoch 61/100 — Step 5000 — Loss: 2.3928\n",
      "Epoch 61/100 — Step 5500 — Loss: 2.6247\n",
      "Epoch 61/100 — Step 6000 — Loss: 2.4080\n",
      "Epoch 61/100 — Step 6500 — Loss: 2.4782\n",
      "Epoch 61/100 — Step 7000 — Loss: 2.4808\n",
      "Epoch 61/100 — Step 7500 — Loss: 2.6204\n",
      "Epoch 61/100 — Step 8000 — Loss: 2.3363\n",
      "Epoch 61/100 — Step 8500 — Loss: 2.5343\n",
      "Epoch 61/100 — Step 9000 — Loss: 2.4954\n",
      "Epoch 61/100 — Step 9500 — Loss: 2.5674\n",
      "Epoch 61/100 — Step 10000 — Loss: 2.2872\n",
      "Epoch 61/100 — Step 10500 — Loss: 2.4320\n",
      "Epoch 61/100 — Step 11000 — Loss: 2.7413\n",
      "Epoch 61/100 — avg_loss: 2.4803, accuracy: 26.63%\n",
      "Epoch 62/100 — Step 500 — Loss: 2.4765\n",
      "Epoch 62/100 — Step 1000 — Loss: 2.3774\n",
      "Epoch 62/100 — Step 1500 — Loss: 2.3762\n",
      "Epoch 62/100 — Step 2000 — Loss: 2.6089\n",
      "Epoch 62/100 — Step 2500 — Loss: 2.3680\n",
      "Epoch 62/100 — Step 3000 — Loss: 2.9620\n",
      "Epoch 62/100 — Step 3500 — Loss: 2.3895\n",
      "Epoch 62/100 — Step 4000 — Loss: 2.4180\n",
      "Epoch 62/100 — Step 4500 — Loss: 2.3150\n",
      "Epoch 62/100 — Step 5000 — Loss: 2.3917\n",
      "Epoch 62/100 — Step 5500 — Loss: 2.6248\n",
      "Epoch 62/100 — Step 6000 — Loss: 2.4078\n",
      "Epoch 62/100 — Step 6500 — Loss: 2.4769\n",
      "Epoch 62/100 — Step 7000 — Loss: 2.4804\n",
      "Epoch 62/100 — Step 7500 — Loss: 2.6188\n",
      "Epoch 62/100 — Step 8000 — Loss: 2.3348\n",
      "Epoch 62/100 — Step 8500 — Loss: 2.5336\n",
      "Epoch 62/100 — Step 9000 — Loss: 2.4929\n",
      "Epoch 62/100 — Step 9500 — Loss: 2.5665\n",
      "Epoch 62/100 — Step 10000 — Loss: 2.2858\n",
      "Epoch 62/100 — Step 10500 — Loss: 2.4315\n",
      "Epoch 62/100 — Step 11000 — Loss: 2.7401\n",
      "Epoch 62/100 — avg_loss: 2.4791, accuracy: 26.65%\n",
      "Epoch 63/100 — Step 500 — Loss: 2.4745\n",
      "Epoch 63/100 — Step 1000 — Loss: 2.3782\n",
      "Epoch 63/100 — Step 1500 — Loss: 2.3757\n",
      "Epoch 63/100 — Step 2000 — Loss: 2.6081\n",
      "Epoch 63/100 — Step 2500 — Loss: 2.3663\n",
      "Epoch 63/100 — Step 3000 — Loss: 2.9618\n",
      "Epoch 63/100 — Step 3500 — Loss: 2.3886\n",
      "Epoch 63/100 — Step 4000 — Loss: 2.4172\n",
      "Epoch 63/100 — Step 4500 — Loss: 2.3124\n",
      "Epoch 63/100 — Step 5000 — Loss: 2.3906\n",
      "Epoch 63/100 — Step 5500 — Loss: 2.6249\n",
      "Epoch 63/100 — Step 6000 — Loss: 2.4076\n",
      "Epoch 63/100 — Step 6500 — Loss: 2.4756\n",
      "Epoch 63/100 — Step 7000 — Loss: 2.4799\n",
      "Epoch 63/100 — Step 7500 — Loss: 2.6172\n",
      "Epoch 63/100 — Step 8000 — Loss: 2.3333\n",
      "Epoch 63/100 — Step 8500 — Loss: 2.5329\n",
      "Epoch 63/100 — Step 9000 — Loss: 2.4905\n",
      "Epoch 63/100 — Step 9500 — Loss: 2.5656\n",
      "Epoch 63/100 — Step 10000 — Loss: 2.2844\n",
      "Epoch 63/100 — Step 10500 — Loss: 2.4309\n",
      "Epoch 63/100 — Step 11000 — Loss: 2.7388\n",
      "Epoch 63/100 — avg_loss: 2.4780, accuracy: 26.66%\n",
      "Epoch 64/100 — Step 500 — Loss: 2.4726\n",
      "Epoch 64/100 — Step 1000 — Loss: 2.3790\n",
      "Epoch 64/100 — Step 1500 — Loss: 2.3753\n",
      "Epoch 64/100 — Step 2000 — Loss: 2.6072\n",
      "Epoch 64/100 — Step 2500 — Loss: 2.3647\n",
      "Epoch 64/100 — Step 3000 — Loss: 2.9614\n",
      "Epoch 64/100 — Step 3500 — Loss: 2.3876\n",
      "Epoch 64/100 — Step 4000 — Loss: 2.4165\n",
      "Epoch 64/100 — Step 4500 — Loss: 2.3100\n",
      "Epoch 64/100 — Step 5000 — Loss: 2.3896\n",
      "Epoch 64/100 — Step 5500 — Loss: 2.6250\n",
      "Epoch 64/100 — Step 6000 — Loss: 2.4075\n",
      "Epoch 64/100 — Step 6500 — Loss: 2.4744\n",
      "Epoch 64/100 — Step 7000 — Loss: 2.4795\n",
      "Epoch 64/100 — Step 7500 — Loss: 2.6156\n",
      "Epoch 64/100 — Step 8000 — Loss: 2.3319\n",
      "Epoch 64/100 — Step 8500 — Loss: 2.5323\n",
      "Epoch 64/100 — Step 9000 — Loss: 2.4881\n",
      "Epoch 64/100 — Step 9500 — Loss: 2.5648\n",
      "Epoch 64/100 — Step 10000 — Loss: 2.2831\n",
      "Epoch 64/100 — Step 10500 — Loss: 2.4304\n",
      "Epoch 64/100 — Step 11000 — Loss: 2.7376\n",
      "Epoch 64/100 — avg_loss: 2.4768, accuracy: 26.68%\n",
      "Epoch 65/100 — Step 500 — Loss: 2.4707\n",
      "Epoch 65/100 — Step 1000 — Loss: 2.3797\n",
      "Epoch 65/100 — Step 1500 — Loss: 2.3748\n",
      "Epoch 65/100 — Step 2000 — Loss: 2.6063\n",
      "Epoch 65/100 — Step 2500 — Loss: 2.3632\n",
      "Epoch 65/100 — Step 3000 — Loss: 2.9611\n",
      "Epoch 65/100 — Step 3500 — Loss: 2.3868\n",
      "Epoch 65/100 — Step 4000 — Loss: 2.4157\n",
      "Epoch 65/100 — Step 4500 — Loss: 2.3076\n",
      "Epoch 65/100 — Step 5000 — Loss: 2.3886\n",
      "Epoch 65/100 — Step 5500 — Loss: 2.6252\n",
      "Epoch 65/100 — Step 6000 — Loss: 2.4073\n",
      "Epoch 65/100 — Step 6500 — Loss: 2.4732\n",
      "Epoch 65/100 — Step 7000 — Loss: 2.4791\n",
      "Epoch 65/100 — Step 7500 — Loss: 2.6141\n",
      "Epoch 65/100 — Step 8000 — Loss: 2.3305\n",
      "Epoch 65/100 — Step 8500 — Loss: 2.5317\n",
      "Epoch 65/100 — Step 9000 — Loss: 2.4857\n",
      "Epoch 65/100 — Step 9500 — Loss: 2.5640\n",
      "Epoch 65/100 — Step 10000 — Loss: 2.2818\n",
      "Epoch 65/100 — Step 10500 — Loss: 2.4299\n",
      "Epoch 65/100 — Step 11000 — Loss: 2.7363\n",
      "Epoch 65/100 — avg_loss: 2.4757, accuracy: 26.69%\n",
      "Epoch 66/100 — Step 500 — Loss: 2.4688\n",
      "Epoch 66/100 — Step 1000 — Loss: 2.3805\n",
      "Epoch 66/100 — Step 1500 — Loss: 2.3744\n",
      "Epoch 66/100 — Step 2000 — Loss: 2.6055\n",
      "Epoch 66/100 — Step 2500 — Loss: 2.3617\n",
      "Epoch 66/100 — Step 3000 — Loss: 2.9608\n",
      "Epoch 66/100 — Step 3500 — Loss: 2.3859\n",
      "Epoch 66/100 — Step 4000 — Loss: 2.4149\n",
      "Epoch 66/100 — Step 4500 — Loss: 2.3052\n",
      "Epoch 66/100 — Step 5000 — Loss: 2.3876\n",
      "Epoch 66/100 — Step 5500 — Loss: 2.6253\n",
      "Epoch 66/100 — Step 6000 — Loss: 2.4072\n",
      "Epoch 66/100 — Step 6500 — Loss: 2.4720\n",
      "Epoch 66/100 — Step 7000 — Loss: 2.4787\n",
      "Epoch 66/100 — Step 7500 — Loss: 2.6127\n",
      "Epoch 66/100 — Step 8000 — Loss: 2.3292\n",
      "Epoch 66/100 — Step 8500 — Loss: 2.5311\n",
      "Epoch 66/100 — Step 9000 — Loss: 2.4835\n",
      "Epoch 66/100 — Step 9500 — Loss: 2.5631\n",
      "Epoch 66/100 — Step 10000 — Loss: 2.2805\n",
      "Epoch 66/100 — Step 10500 — Loss: 2.4294\n",
      "Epoch 66/100 — Step 11000 — Loss: 2.7351\n",
      "Epoch 66/100 — avg_loss: 2.4746, accuracy: 26.70%\n",
      "Epoch 67/100 — Step 500 — Loss: 2.4669\n",
      "Epoch 67/100 — Step 1000 — Loss: 2.3812\n",
      "Epoch 67/100 — Step 1500 — Loss: 2.3740\n",
      "Epoch 67/100 — Step 2000 — Loss: 2.6047\n",
      "Epoch 67/100 — Step 2500 — Loss: 2.3602\n",
      "Epoch 67/100 — Step 3000 — Loss: 2.9604\n",
      "Epoch 67/100 — Step 3500 — Loss: 2.3850\n",
      "Epoch 67/100 — Step 4000 — Loss: 2.4142\n",
      "Epoch 67/100 — Step 4500 — Loss: 2.3030\n",
      "Epoch 67/100 — Step 5000 — Loss: 2.3866\n",
      "Epoch 67/100 — Step 5500 — Loss: 2.6255\n",
      "Epoch 67/100 — Step 6000 — Loss: 2.4071\n",
      "Epoch 67/100 — Step 6500 — Loss: 2.4709\n",
      "Epoch 67/100 — Step 7000 — Loss: 2.4783\n",
      "Epoch 67/100 — Step 7500 — Loss: 2.6112\n",
      "Epoch 67/100 — Step 8000 — Loss: 2.3279\n",
      "Epoch 67/100 — Step 8500 — Loss: 2.5305\n",
      "Epoch 67/100 — Step 9000 — Loss: 2.4812\n",
      "Epoch 67/100 — Step 9500 — Loss: 2.5623\n",
      "Epoch 67/100 — Step 10000 — Loss: 2.2793\n",
      "Epoch 67/100 — Step 10500 — Loss: 2.4290\n",
      "Epoch 67/100 — Step 11000 — Loss: 2.7339\n",
      "Epoch 67/100 — avg_loss: 2.4736, accuracy: 26.71%\n",
      "Epoch 68/100 — Step 500 — Loss: 2.4651\n",
      "Epoch 68/100 — Step 1000 — Loss: 2.3819\n",
      "Epoch 68/100 — Step 1500 — Loss: 2.3735\n",
      "Epoch 68/100 — Step 2000 — Loss: 2.6039\n",
      "Epoch 68/100 — Step 2500 — Loss: 2.3587\n",
      "Epoch 68/100 — Step 3000 — Loss: 2.9600\n",
      "Epoch 68/100 — Step 3500 — Loss: 2.3842\n",
      "Epoch 68/100 — Step 4000 — Loss: 2.4134\n",
      "Epoch 68/100 — Step 4500 — Loss: 2.3008\n",
      "Epoch 68/100 — Step 5000 — Loss: 2.3856\n",
      "Epoch 68/100 — Step 5500 — Loss: 2.6256\n",
      "Epoch 68/100 — Step 6000 — Loss: 2.4070\n",
      "Epoch 68/100 — Step 6500 — Loss: 2.4698\n",
      "Epoch 68/100 — Step 7000 — Loss: 2.4779\n",
      "Epoch 68/100 — Step 7500 — Loss: 2.6098\n",
      "Epoch 68/100 — Step 8000 — Loss: 2.3267\n",
      "Epoch 68/100 — Step 8500 — Loss: 2.5299\n",
      "Epoch 68/100 — Step 9000 — Loss: 2.4790\n",
      "Epoch 68/100 — Step 9500 — Loss: 2.5616\n",
      "Epoch 68/100 — Step 10000 — Loss: 2.2780\n",
      "Epoch 68/100 — Step 10500 — Loss: 2.4285\n",
      "Epoch 68/100 — Step 11000 — Loss: 2.7327\n",
      "Epoch 68/100 — avg_loss: 2.4725, accuracy: 26.73%\n",
      "Epoch 69/100 — Step 500 — Loss: 2.4633\n",
      "Epoch 69/100 — Step 1000 — Loss: 2.3826\n",
      "Epoch 69/100 — Step 1500 — Loss: 2.3731\n",
      "Epoch 69/100 — Step 2000 — Loss: 2.6031\n",
      "Epoch 69/100 — Step 2500 — Loss: 2.3573\n",
      "Epoch 69/100 — Step 3000 — Loss: 2.9595\n",
      "Epoch 69/100 — Step 3500 — Loss: 2.3834\n",
      "Epoch 69/100 — Step 4000 — Loss: 2.4127\n",
      "Epoch 69/100 — Step 4500 — Loss: 2.2986\n",
      "Epoch 69/100 — Step 5000 — Loss: 2.3847\n",
      "Epoch 69/100 — Step 5500 — Loss: 2.6258\n",
      "Epoch 69/100 — Step 6000 — Loss: 2.4069\n",
      "Epoch 69/100 — Step 6500 — Loss: 2.4688\n",
      "Epoch 69/100 — Step 7000 — Loss: 2.4775\n",
      "Epoch 69/100 — Step 7500 — Loss: 2.6084\n",
      "Epoch 69/100 — Step 8000 — Loss: 2.3255\n",
      "Epoch 69/100 — Step 8500 — Loss: 2.5294\n",
      "Epoch 69/100 — Step 9000 — Loss: 2.4769\n",
      "Epoch 69/100 — Step 9500 — Loss: 2.5608\n",
      "Epoch 69/100 — Step 10000 — Loss: 2.2768\n",
      "Epoch 69/100 — Step 10500 — Loss: 2.4281\n",
      "Epoch 69/100 — Step 11000 — Loss: 2.7315\n",
      "Epoch 69/100 — avg_loss: 2.4715, accuracy: 26.74%\n",
      "Epoch 70/100 — Step 500 — Loss: 2.4615\n",
      "Epoch 70/100 — Step 1000 — Loss: 2.3832\n",
      "Epoch 70/100 — Step 1500 — Loss: 2.3728\n",
      "Epoch 70/100 — Step 2000 — Loss: 2.6024\n",
      "Epoch 70/100 — Step 2500 — Loss: 2.3559\n",
      "Epoch 70/100 — Step 3000 — Loss: 2.9591\n",
      "Epoch 70/100 — Step 3500 — Loss: 2.3826\n",
      "Epoch 70/100 — Step 4000 — Loss: 2.4120\n",
      "Epoch 70/100 — Step 4500 — Loss: 2.2966\n",
      "Epoch 70/100 — Step 5000 — Loss: 2.3837\n",
      "Epoch 70/100 — Step 5500 — Loss: 2.6259\n",
      "Epoch 70/100 — Step 6000 — Loss: 2.4069\n",
      "Epoch 70/100 — Step 6500 — Loss: 2.4678\n",
      "Epoch 70/100 — Step 7000 — Loss: 2.4771\n",
      "Epoch 70/100 — Step 7500 — Loss: 2.6070\n",
      "Epoch 70/100 — Step 8000 — Loss: 2.3243\n",
      "Epoch 70/100 — Step 8500 — Loss: 2.5288\n",
      "Epoch 70/100 — Step 9000 — Loss: 2.4748\n",
      "Epoch 70/100 — Step 9500 — Loss: 2.5600\n",
      "Epoch 70/100 — Step 10000 — Loss: 2.2757\n",
      "Epoch 70/100 — Step 10500 — Loss: 2.4277\n",
      "Epoch 70/100 — Step 11000 — Loss: 2.7304\n",
      "Epoch 70/100 — avg_loss: 2.4705, accuracy: 26.76%\n",
      "Epoch 71/100 — Step 500 — Loss: 2.4597\n",
      "Epoch 71/100 — Step 1000 — Loss: 2.3839\n",
      "Epoch 71/100 — Step 1500 — Loss: 2.3724\n",
      "Epoch 71/100 — Step 2000 — Loss: 2.6016\n",
      "Epoch 71/100 — Step 2500 — Loss: 2.3546\n",
      "Epoch 71/100 — Step 3000 — Loss: 2.9586\n",
      "Epoch 71/100 — Step 3500 — Loss: 2.3818\n",
      "Epoch 71/100 — Step 4000 — Loss: 2.4113\n",
      "Epoch 71/100 — Step 4500 — Loss: 2.2945\n",
      "Epoch 71/100 — Step 5000 — Loss: 2.3828\n",
      "Epoch 71/100 — Step 5500 — Loss: 2.6261\n",
      "Epoch 71/100 — Step 6000 — Loss: 2.4068\n",
      "Epoch 71/100 — Step 6500 — Loss: 2.4668\n",
      "Epoch 71/100 — Step 7000 — Loss: 2.4768\n",
      "Epoch 71/100 — Step 7500 — Loss: 2.6057\n",
      "Epoch 71/100 — Step 8000 — Loss: 2.3232\n",
      "Epoch 71/100 — Step 8500 — Loss: 2.5283\n",
      "Epoch 71/100 — Step 9000 — Loss: 2.4727\n",
      "Epoch 71/100 — Step 9500 — Loss: 2.5593\n",
      "Epoch 71/100 — Step 10000 — Loss: 2.2745\n",
      "Epoch 71/100 — Step 10500 — Loss: 2.4273\n",
      "Epoch 71/100 — Step 11000 — Loss: 2.7292\n",
      "Epoch 71/100 — avg_loss: 2.4696, accuracy: 26.77%\n",
      "Epoch 72/100 — Step 500 — Loss: 2.4580\n",
      "Epoch 72/100 — Step 1000 — Loss: 2.3845\n",
      "Epoch 72/100 — Step 1500 — Loss: 2.3720\n",
      "Epoch 72/100 — Step 2000 — Loss: 2.6009\n",
      "Epoch 72/100 — Step 2500 — Loss: 2.3533\n",
      "Epoch 72/100 — Step 3000 — Loss: 2.9582\n",
      "Epoch 72/100 — Step 3500 — Loss: 2.3810\n",
      "Epoch 72/100 — Step 4000 — Loss: 2.4106\n",
      "Epoch 72/100 — Step 4500 — Loss: 2.2926\n",
      "Epoch 72/100 — Step 5000 — Loss: 2.3819\n",
      "Epoch 72/100 — Step 5500 — Loss: 2.6262\n",
      "Epoch 72/100 — Step 6000 — Loss: 2.4068\n",
      "Epoch 72/100 — Step 6500 — Loss: 2.4658\n",
      "Epoch 72/100 — Step 7000 — Loss: 2.4764\n",
      "Epoch 72/100 — Step 7500 — Loss: 2.6044\n",
      "Epoch 72/100 — Step 8000 — Loss: 2.3221\n",
      "Epoch 72/100 — Step 8500 — Loss: 2.5278\n",
      "Epoch 72/100 — Step 9000 — Loss: 2.4707\n",
      "Epoch 72/100 — Step 9500 — Loss: 2.5586\n",
      "Epoch 72/100 — Step 10000 — Loss: 2.2733\n",
      "Epoch 72/100 — Step 10500 — Loss: 2.4270\n",
      "Epoch 72/100 — Step 11000 — Loss: 2.7281\n",
      "Epoch 72/100 — avg_loss: 2.4686, accuracy: 26.78%\n",
      "Epoch 73/100 — Step 500 — Loss: 2.4563\n",
      "Epoch 73/100 — Step 1000 — Loss: 2.3851\n",
      "Epoch 73/100 — Step 1500 — Loss: 2.3716\n",
      "Epoch 73/100 — Step 2000 — Loss: 2.6002\n",
      "Epoch 73/100 — Step 2500 — Loss: 2.3520\n",
      "Epoch 73/100 — Step 3000 — Loss: 2.9577\n",
      "Epoch 73/100 — Step 3500 — Loss: 2.3803\n",
      "Epoch 73/100 — Step 4000 — Loss: 2.4100\n",
      "Epoch 73/100 — Step 4500 — Loss: 2.2906\n",
      "Epoch 73/100 — Step 5000 — Loss: 2.3810\n",
      "Epoch 73/100 — Step 5500 — Loss: 2.6264\n",
      "Epoch 73/100 — Step 6000 — Loss: 2.4068\n",
      "Epoch 73/100 — Step 6500 — Loss: 2.4649\n",
      "Epoch 73/100 — Step 7000 — Loss: 2.4761\n",
      "Epoch 73/100 — Step 7500 — Loss: 2.6031\n",
      "Epoch 73/100 — Step 8000 — Loss: 2.3210\n",
      "Epoch 73/100 — Step 8500 — Loss: 2.5273\n",
      "Epoch 73/100 — Step 9000 — Loss: 2.4687\n",
      "Epoch 73/100 — Step 9500 — Loss: 2.5579\n",
      "Epoch 73/100 — Step 10000 — Loss: 2.2722\n",
      "Epoch 73/100 — Step 10500 — Loss: 2.4266\n",
      "Epoch 73/100 — Step 11000 — Loss: 2.7269\n",
      "Epoch 73/100 — avg_loss: 2.4677, accuracy: 26.79%\n",
      "Epoch 74/100 — Step 500 — Loss: 2.4546\n",
      "Epoch 74/100 — Step 1000 — Loss: 2.3857\n",
      "Epoch 74/100 — Step 1500 — Loss: 2.3712\n",
      "Epoch 74/100 — Step 2000 — Loss: 2.5995\n",
      "Epoch 74/100 — Step 2500 — Loss: 2.3508\n",
      "Epoch 74/100 — Step 3000 — Loss: 2.9572\n",
      "Epoch 74/100 — Step 3500 — Loss: 2.3796\n",
      "Epoch 74/100 — Step 4000 — Loss: 2.4093\n",
      "Epoch 74/100 — Step 4500 — Loss: 2.2888\n",
      "Epoch 74/100 — Step 5000 — Loss: 2.3801\n",
      "Epoch 74/100 — Step 5500 — Loss: 2.6265\n",
      "Epoch 74/100 — Step 6000 — Loss: 2.4068\n",
      "Epoch 74/100 — Step 6500 — Loss: 2.4640\n",
      "Epoch 74/100 — Step 7000 — Loss: 2.4757\n",
      "Epoch 74/100 — Step 7500 — Loss: 2.6019\n",
      "Epoch 74/100 — Step 8000 — Loss: 2.3200\n",
      "Epoch 74/100 — Step 8500 — Loss: 2.5267\n",
      "Epoch 74/100 — Step 9000 — Loss: 2.4667\n",
      "Epoch 74/100 — Step 9500 — Loss: 2.5572\n",
      "Epoch 74/100 — Step 10000 — Loss: 2.2711\n",
      "Epoch 74/100 — Step 10500 — Loss: 2.4263\n",
      "Epoch 74/100 — Step 11000 — Loss: 2.7258\n",
      "Epoch 74/100 — avg_loss: 2.4668, accuracy: 26.80%\n",
      "Epoch 75/100 — Step 500 — Loss: 2.4529\n",
      "Epoch 75/100 — Step 1000 — Loss: 2.3862\n",
      "Epoch 75/100 — Step 1500 — Loss: 2.3709\n",
      "Epoch 75/100 — Step 2000 — Loss: 2.5988\n",
      "Epoch 75/100 — Step 2500 — Loss: 2.3496\n",
      "Epoch 75/100 — Step 3000 — Loss: 2.9567\n",
      "Epoch 75/100 — Step 3500 — Loss: 2.3788\n",
      "Epoch 75/100 — Step 4000 — Loss: 2.4086\n",
      "Epoch 75/100 — Step 4500 — Loss: 2.2869\n",
      "Epoch 75/100 — Step 5000 — Loss: 2.3792\n",
      "Epoch 75/100 — Step 5500 — Loss: 2.6267\n",
      "Epoch 75/100 — Step 6000 — Loss: 2.4068\n",
      "Epoch 75/100 — Step 6500 — Loss: 2.4631\n",
      "Epoch 75/100 — Step 7000 — Loss: 2.4754\n",
      "Epoch 75/100 — Step 7500 — Loss: 2.6006\n",
      "Epoch 75/100 — Step 8000 — Loss: 2.3190\n",
      "Epoch 75/100 — Step 8500 — Loss: 2.5262\n",
      "Epoch 75/100 — Step 9000 — Loss: 2.4648\n",
      "Epoch 75/100 — Step 9500 — Loss: 2.5565\n",
      "Epoch 75/100 — Step 10000 — Loss: 2.2700\n",
      "Epoch 75/100 — Step 10500 — Loss: 2.4260\n",
      "Epoch 75/100 — Step 11000 — Loss: 2.7247\n",
      "Epoch 75/100 — avg_loss: 2.4659, accuracy: 26.81%\n",
      "Epoch 76/100 — Step 500 — Loss: 2.4513\n",
      "Epoch 76/100 — Step 1000 — Loss: 2.3867\n",
      "Epoch 76/100 — Step 1500 — Loss: 2.3705\n",
      "Epoch 76/100 — Step 2000 — Loss: 2.5981\n",
      "Epoch 76/100 — Step 2500 — Loss: 2.3484\n",
      "Epoch 76/100 — Step 3000 — Loss: 2.9562\n",
      "Epoch 76/100 — Step 3500 — Loss: 2.3782\n",
      "Epoch 76/100 — Step 4000 — Loss: 2.4080\n",
      "Epoch 76/100 — Step 4500 — Loss: 2.2851\n",
      "Epoch 76/100 — Step 5000 — Loss: 2.3783\n",
      "Epoch 76/100 — Step 5500 — Loss: 2.6268\n",
      "Epoch 76/100 — Step 6000 — Loss: 2.4068\n",
      "Epoch 76/100 — Step 6500 — Loss: 2.4622\n",
      "Epoch 76/100 — Step 7000 — Loss: 2.4750\n",
      "Epoch 76/100 — Step 7500 — Loss: 2.5994\n",
      "Epoch 76/100 — Step 8000 — Loss: 2.3180\n",
      "Epoch 76/100 — Step 8500 — Loss: 2.5257\n",
      "Epoch 76/100 — Step 9000 — Loss: 2.4629\n",
      "Epoch 76/100 — Step 9500 — Loss: 2.5558\n",
      "Epoch 76/100 — Step 10000 — Loss: 2.2689\n",
      "Epoch 76/100 — Step 10500 — Loss: 2.4257\n",
      "Epoch 76/100 — Step 11000 — Loss: 2.7236\n",
      "Epoch 76/100 — avg_loss: 2.4651, accuracy: 26.82%\n",
      "Epoch 77/100 — Step 500 — Loss: 2.4497\n",
      "Epoch 77/100 — Step 1000 — Loss: 2.3872\n",
      "Epoch 77/100 — Step 1500 — Loss: 2.3702\n",
      "Epoch 77/100 — Step 2000 — Loss: 2.5974\n",
      "Epoch 77/100 — Step 2500 — Loss: 2.3473\n",
      "Epoch 77/100 — Step 3000 — Loss: 2.9556\n",
      "Epoch 77/100 — Step 3500 — Loss: 2.3775\n",
      "Epoch 77/100 — Step 4000 — Loss: 2.4073\n",
      "Epoch 77/100 — Step 4500 — Loss: 2.2834\n",
      "Epoch 77/100 — Step 5000 — Loss: 2.3775\n",
      "Epoch 77/100 — Step 5500 — Loss: 2.6269\n",
      "Epoch 77/100 — Step 6000 — Loss: 2.4068\n",
      "Epoch 77/100 — Step 6500 — Loss: 2.4614\n",
      "Epoch 77/100 — Step 7000 — Loss: 2.4747\n",
      "Epoch 77/100 — Step 7500 — Loss: 2.5982\n",
      "Epoch 77/100 — Step 8000 — Loss: 2.3171\n",
      "Epoch 77/100 — Step 8500 — Loss: 2.5252\n",
      "Epoch 77/100 — Step 9000 — Loss: 2.4611\n",
      "Epoch 77/100 — Step 9500 — Loss: 2.5552\n",
      "Epoch 77/100 — Step 10000 — Loss: 2.2678\n",
      "Epoch 77/100 — Step 10500 — Loss: 2.4254\n",
      "Epoch 77/100 — Step 11000 — Loss: 2.7226\n",
      "Epoch 77/100 — avg_loss: 2.4642, accuracy: 26.83%\n",
      "Epoch 78/100 — Step 500 — Loss: 2.4480\n",
      "Epoch 78/100 — Step 1000 — Loss: 2.3877\n",
      "Epoch 78/100 — Step 1500 — Loss: 2.3698\n",
      "Epoch 78/100 — Step 2000 — Loss: 2.5967\n",
      "Epoch 78/100 — Step 2500 — Loss: 2.3461\n",
      "Epoch 78/100 — Step 3000 — Loss: 2.9551\n",
      "Epoch 78/100 — Step 3500 — Loss: 2.3768\n",
      "Epoch 78/100 — Step 4000 — Loss: 2.4067\n",
      "Epoch 78/100 — Step 4500 — Loss: 2.2817\n",
      "Epoch 78/100 — Step 5000 — Loss: 2.3766\n",
      "Epoch 78/100 — Step 5500 — Loss: 2.6271\n",
      "Epoch 78/100 — Step 6000 — Loss: 2.4069\n",
      "Epoch 78/100 — Step 6500 — Loss: 2.4606\n",
      "Epoch 78/100 — Step 7000 — Loss: 2.4744\n",
      "Epoch 78/100 — Step 7500 — Loss: 2.5971\n",
      "Epoch 78/100 — Step 8000 — Loss: 2.3162\n",
      "Epoch 78/100 — Step 8500 — Loss: 2.5247\n",
      "Epoch 78/100 — Step 9000 — Loss: 2.4593\n",
      "Epoch 78/100 — Step 9500 — Loss: 2.5545\n",
      "Epoch 78/100 — Step 10000 — Loss: 2.2667\n",
      "Epoch 78/100 — Step 10500 — Loss: 2.4251\n",
      "Epoch 78/100 — Step 11000 — Loss: 2.7215\n",
      "Epoch 78/100 — avg_loss: 2.4634, accuracy: 26.84%\n",
      "Epoch 79/100 — Step 500 — Loss: 2.4465\n",
      "Epoch 79/100 — Step 1000 — Loss: 2.3882\n",
      "Epoch 79/100 — Step 1500 — Loss: 2.3695\n",
      "Epoch 79/100 — Step 2000 — Loss: 2.5961\n",
      "Epoch 79/100 — Step 2500 — Loss: 2.3451\n",
      "Epoch 79/100 — Step 3000 — Loss: 2.9546\n",
      "Epoch 79/100 — Step 3500 — Loss: 2.3761\n",
      "Epoch 79/100 — Step 4000 — Loss: 2.4061\n",
      "Epoch 79/100 — Step 4500 — Loss: 2.2801\n",
      "Epoch 79/100 — Step 5000 — Loss: 2.3758\n",
      "Epoch 79/100 — Step 5500 — Loss: 2.6272\n",
      "Epoch 79/100 — Step 6000 — Loss: 2.4069\n",
      "Epoch 79/100 — Step 6500 — Loss: 2.4598\n",
      "Epoch 79/100 — Step 7000 — Loss: 2.4741\n",
      "Epoch 79/100 — Step 7500 — Loss: 2.5959\n",
      "Epoch 79/100 — Step 8000 — Loss: 2.3153\n",
      "Epoch 79/100 — Step 8500 — Loss: 2.5243\n",
      "Epoch 79/100 — Step 9000 — Loss: 2.4575\n",
      "Epoch 79/100 — Step 9500 — Loss: 2.5539\n",
      "Epoch 79/100 — Step 10000 — Loss: 2.2657\n",
      "Epoch 79/100 — Step 10500 — Loss: 2.4248\n",
      "Epoch 79/100 — Step 11000 — Loss: 2.7204\n",
      "Epoch 79/100 — avg_loss: 2.4626, accuracy: 26.85%\n",
      "Epoch 80/100 — Step 500 — Loss: 2.4449\n",
      "Epoch 80/100 — Step 1000 — Loss: 2.3886\n",
      "Epoch 80/100 — Step 1500 — Loss: 2.3692\n",
      "Epoch 80/100 — Step 2000 — Loss: 2.5954\n",
      "Epoch 80/100 — Step 2500 — Loss: 2.3440\n",
      "Epoch 80/100 — Step 3000 — Loss: 2.9540\n",
      "Epoch 80/100 — Step 3500 — Loss: 2.3755\n",
      "Epoch 80/100 — Step 4000 — Loss: 2.4055\n",
      "Epoch 80/100 — Step 4500 — Loss: 2.2785\n",
      "Epoch 80/100 — Step 5000 — Loss: 2.3750\n",
      "Epoch 80/100 — Step 5500 — Loss: 2.6273\n",
      "Epoch 80/100 — Step 6000 — Loss: 2.4069\n",
      "Epoch 80/100 — Step 6500 — Loss: 2.4590\n",
      "Epoch 80/100 — Step 7000 — Loss: 2.4738\n",
      "Epoch 80/100 — Step 7500 — Loss: 2.5948\n",
      "Epoch 80/100 — Step 8000 — Loss: 2.3144\n",
      "Epoch 80/100 — Step 8500 — Loss: 2.5238\n",
      "Epoch 80/100 — Step 9000 — Loss: 2.4557\n",
      "Epoch 80/100 — Step 9500 — Loss: 2.5533\n",
      "Epoch 80/100 — Step 10000 — Loss: 2.2646\n",
      "Epoch 80/100 — Step 10500 — Loss: 2.4246\n",
      "Epoch 80/100 — Step 11000 — Loss: 2.7194\n",
      "Epoch 80/100 — avg_loss: 2.4618, accuracy: 26.86%\n",
      "Epoch 81/100 — Step 500 — Loss: 2.4433\n",
      "Epoch 81/100 — Step 1000 — Loss: 2.3890\n",
      "Epoch 81/100 — Step 1500 — Loss: 2.3688\n",
      "Epoch 81/100 — Step 2000 — Loss: 2.5948\n",
      "Epoch 81/100 — Step 2500 — Loss: 2.3430\n",
      "Epoch 81/100 — Step 3000 — Loss: 2.9535\n",
      "Epoch 81/100 — Step 3500 — Loss: 2.3749\n",
      "Epoch 81/100 — Step 4000 — Loss: 2.4049\n",
      "Epoch 81/100 — Step 4500 — Loss: 2.2769\n",
      "Epoch 81/100 — Step 5000 — Loss: 2.3742\n",
      "Epoch 81/100 — Step 5500 — Loss: 2.6274\n",
      "Epoch 81/100 — Step 6000 — Loss: 2.4070\n",
      "Epoch 81/100 — Step 6500 — Loss: 2.4582\n",
      "Epoch 81/100 — Step 7000 — Loss: 2.4735\n",
      "Epoch 81/100 — Step 7500 — Loss: 2.5937\n",
      "Epoch 81/100 — Step 8000 — Loss: 2.3136\n",
      "Epoch 81/100 — Step 8500 — Loss: 2.5233\n",
      "Epoch 81/100 — Step 9000 — Loss: 2.4540\n",
      "Epoch 81/100 — Step 9500 — Loss: 2.5527\n",
      "Epoch 81/100 — Step 10000 — Loss: 2.2636\n",
      "Epoch 81/100 — Step 10500 — Loss: 2.4243\n",
      "Epoch 81/100 — Step 11000 — Loss: 2.7184\n",
      "Epoch 81/100 — avg_loss: 2.4610, accuracy: 26.87%\n",
      "Epoch 82/100 — Step 500 — Loss: 2.4418\n",
      "Epoch 82/100 — Step 1000 — Loss: 2.3894\n",
      "Epoch 82/100 — Step 1500 — Loss: 2.3685\n",
      "Epoch 82/100 — Step 2000 — Loss: 2.5941\n",
      "Epoch 82/100 — Step 2500 — Loss: 2.3420\n",
      "Epoch 82/100 — Step 3000 — Loss: 2.9530\n",
      "Epoch 82/100 — Step 3500 — Loss: 2.3743\n",
      "Epoch 82/100 — Step 4000 — Loss: 2.4043\n",
      "Epoch 82/100 — Step 4500 — Loss: 2.2753\n",
      "Epoch 82/100 — Step 5000 — Loss: 2.3734\n",
      "Epoch 82/100 — Step 5500 — Loss: 2.6275\n",
      "Epoch 82/100 — Step 6000 — Loss: 2.4071\n",
      "Epoch 82/100 — Step 6500 — Loss: 2.4575\n",
      "Epoch 82/100 — Step 7000 — Loss: 2.4732\n",
      "Epoch 82/100 — Step 7500 — Loss: 2.5926\n",
      "Epoch 82/100 — Step 8000 — Loss: 2.3128\n",
      "Epoch 82/100 — Step 8500 — Loss: 2.5228\n",
      "Epoch 82/100 — Step 9000 — Loss: 2.4523\n",
      "Epoch 82/100 — Step 9500 — Loss: 2.5521\n",
      "Epoch 82/100 — Step 10000 — Loss: 2.2626\n",
      "Epoch 82/100 — Step 10500 — Loss: 2.4241\n",
      "Epoch 82/100 — Step 11000 — Loss: 2.7174\n",
      "Epoch 82/100 — avg_loss: 2.4602, accuracy: 26.88%\n",
      "Epoch 83/100 — Step 500 — Loss: 2.4403\n",
      "Epoch 83/100 — Step 1000 — Loss: 2.3898\n",
      "Epoch 83/100 — Step 1500 — Loss: 2.3682\n",
      "Epoch 83/100 — Step 2000 — Loss: 2.5935\n",
      "Epoch 83/100 — Step 2500 — Loss: 2.3410\n",
      "Epoch 83/100 — Step 3000 — Loss: 2.9524\n",
      "Epoch 83/100 — Step 3500 — Loss: 2.3736\n",
      "Epoch 83/100 — Step 4000 — Loss: 2.4037\n",
      "Epoch 83/100 — Step 4500 — Loss: 2.2738\n",
      "Epoch 83/100 — Step 5000 — Loss: 2.3726\n",
      "Epoch 83/100 — Step 5500 — Loss: 2.6276\n",
      "Epoch 83/100 — Step 6000 — Loss: 2.4071\n",
      "Epoch 83/100 — Step 6500 — Loss: 2.4567\n",
      "Epoch 83/100 — Step 7000 — Loss: 2.4729\n",
      "Epoch 83/100 — Step 7500 — Loss: 2.5915\n",
      "Epoch 83/100 — Step 8000 — Loss: 2.3120\n",
      "Epoch 83/100 — Step 8500 — Loss: 2.5223\n",
      "Epoch 83/100 — Step 9000 — Loss: 2.4507\n",
      "Epoch 83/100 — Step 9500 — Loss: 2.5515\n",
      "Epoch 83/100 — Step 10000 — Loss: 2.2615\n",
      "Epoch 83/100 — Step 10500 — Loss: 2.4239\n",
      "Epoch 83/100 — Step 11000 — Loss: 2.7164\n",
      "Epoch 83/100 — avg_loss: 2.4594, accuracy: 26.89%\n",
      "Epoch 84/100 — Step 500 — Loss: 2.4388\n",
      "Epoch 84/100 — Step 1000 — Loss: 2.3901\n",
      "Epoch 84/100 — Step 1500 — Loss: 2.3679\n",
      "Epoch 84/100 — Step 2000 — Loss: 2.5929\n",
      "Epoch 84/100 — Step 2500 — Loss: 2.3400\n",
      "Epoch 84/100 — Step 3000 — Loss: 2.9519\n",
      "Epoch 84/100 — Step 3500 — Loss: 2.3731\n",
      "Epoch 84/100 — Step 4000 — Loss: 2.4031\n",
      "Epoch 84/100 — Step 4500 — Loss: 2.2724\n",
      "Epoch 84/100 — Step 5000 — Loss: 2.3718\n",
      "Epoch 84/100 — Step 5500 — Loss: 2.6277\n",
      "Epoch 84/100 — Step 6000 — Loss: 2.4072\n",
      "Epoch 84/100 — Step 6500 — Loss: 2.4560\n",
      "Epoch 84/100 — Step 7000 — Loss: 2.4726\n",
      "Epoch 84/100 — Step 7500 — Loss: 2.5905\n",
      "Epoch 84/100 — Step 8000 — Loss: 2.3112\n",
      "Epoch 84/100 — Step 8500 — Loss: 2.5219\n",
      "Epoch 84/100 — Step 9000 — Loss: 2.4490\n",
      "Epoch 84/100 — Step 9500 — Loss: 2.5509\n",
      "Epoch 84/100 — Step 10000 — Loss: 2.2605\n",
      "Epoch 84/100 — Step 10500 — Loss: 2.4237\n",
      "Epoch 84/100 — Step 11000 — Loss: 2.7154\n",
      "Epoch 84/100 — avg_loss: 2.4587, accuracy: 26.90%\n",
      "Epoch 85/100 — Step 500 — Loss: 2.4373\n",
      "Epoch 85/100 — Step 1000 — Loss: 2.3904\n",
      "Epoch 85/100 — Step 1500 — Loss: 2.3676\n",
      "Epoch 85/100 — Step 2000 — Loss: 2.5923\n",
      "Epoch 85/100 — Step 2500 — Loss: 2.3391\n",
      "Epoch 85/100 — Step 3000 — Loss: 2.9513\n",
      "Epoch 85/100 — Step 3500 — Loss: 2.3725\n",
      "Epoch 85/100 — Step 4000 — Loss: 2.4025\n",
      "Epoch 85/100 — Step 4500 — Loss: 2.2709\n",
      "Epoch 85/100 — Step 5000 — Loss: 2.3710\n",
      "Epoch 85/100 — Step 5500 — Loss: 2.6278\n",
      "Epoch 85/100 — Step 6000 — Loss: 2.4073\n",
      "Epoch 85/100 — Step 6500 — Loss: 2.4553\n",
      "Epoch 85/100 — Step 7000 — Loss: 2.4723\n",
      "Epoch 85/100 — Step 7500 — Loss: 2.5895\n",
      "Epoch 85/100 — Step 8000 — Loss: 2.3104\n",
      "Epoch 85/100 — Step 8500 — Loss: 2.5214\n",
      "Epoch 85/100 — Step 9000 — Loss: 2.4474\n",
      "Epoch 85/100 — Step 9500 — Loss: 2.5503\n",
      "Epoch 85/100 — Step 10000 — Loss: 2.2595\n",
      "Epoch 85/100 — Step 10500 — Loss: 2.4234\n",
      "Epoch 85/100 — Step 11000 — Loss: 2.7144\n",
      "Epoch 85/100 — avg_loss: 2.4580, accuracy: 26.91%\n",
      "Epoch 86/100 — Step 500 — Loss: 2.4359\n",
      "Epoch 86/100 — Step 1000 — Loss: 2.3907\n",
      "Epoch 86/100 — Step 1500 — Loss: 2.3672\n",
      "Epoch 86/100 — Step 2000 — Loss: 2.5917\n",
      "Epoch 86/100 — Step 2500 — Loss: 2.3382\n",
      "Epoch 86/100 — Step 3000 — Loss: 2.9508\n",
      "Epoch 86/100 — Step 3500 — Loss: 2.3719\n",
      "Epoch 86/100 — Step 4000 — Loss: 2.4019\n",
      "Epoch 86/100 — Step 4500 — Loss: 2.2695\n",
      "Epoch 86/100 — Step 5000 — Loss: 2.3702\n",
      "Epoch 86/100 — Step 5500 — Loss: 2.6279\n",
      "Epoch 86/100 — Step 6000 — Loss: 2.4073\n",
      "Epoch 86/100 — Step 6500 — Loss: 2.4546\n",
      "Epoch 86/100 — Step 7000 — Loss: 2.4720\n",
      "Epoch 86/100 — Step 7500 — Loss: 2.5885\n",
      "Epoch 86/100 — Step 8000 — Loss: 2.3097\n",
      "Epoch 86/100 — Step 8500 — Loss: 2.5209\n",
      "Epoch 86/100 — Step 9000 — Loss: 2.4459\n",
      "Epoch 86/100 — Step 9500 — Loss: 2.5498\n",
      "Epoch 86/100 — Step 10000 — Loss: 2.2585\n",
      "Epoch 86/100 — Step 10500 — Loss: 2.4233\n",
      "Epoch 86/100 — Step 11000 — Loss: 2.7134\n",
      "Epoch 86/100 — avg_loss: 2.4573, accuracy: 26.92%\n",
      "Epoch 87/100 — Step 500 — Loss: 2.4345\n",
      "Epoch 87/100 — Step 1000 — Loss: 2.3910\n",
      "Epoch 87/100 — Step 1500 — Loss: 2.3669\n",
      "Epoch 87/100 — Step 2000 — Loss: 2.5911\n",
      "Epoch 87/100 — Step 2500 — Loss: 2.3373\n",
      "Epoch 87/100 — Step 3000 — Loss: 2.9503\n",
      "Epoch 87/100 — Step 3500 — Loss: 2.3713\n",
      "Epoch 87/100 — Step 4000 — Loss: 2.4014\n",
      "Epoch 87/100 — Step 4500 — Loss: 2.2682\n",
      "Epoch 87/100 — Step 5000 — Loss: 2.3695\n",
      "Epoch 87/100 — Step 5500 — Loss: 2.6279\n",
      "Epoch 87/100 — Step 6000 — Loss: 2.4074\n",
      "Epoch 87/100 — Step 6500 — Loss: 2.4540\n",
      "Epoch 87/100 — Step 7000 — Loss: 2.4717\n",
      "Epoch 87/100 — Step 7500 — Loss: 2.5875\n",
      "Epoch 87/100 — Step 8000 — Loss: 2.3090\n",
      "Epoch 87/100 — Step 8500 — Loss: 2.5205\n",
      "Epoch 87/100 — Step 9000 — Loss: 2.4443\n",
      "Epoch 87/100 — Step 9500 — Loss: 2.5492\n",
      "Epoch 87/100 — Step 10000 — Loss: 2.2575\n",
      "Epoch 87/100 — Step 10500 — Loss: 2.4231\n",
      "Epoch 87/100 — Step 11000 — Loss: 2.7125\n",
      "Epoch 87/100 — avg_loss: 2.4566, accuracy: 26.92%\n",
      "Epoch 88/100 — Step 500 — Loss: 2.4330\n",
      "Epoch 88/100 — Step 1000 — Loss: 2.3913\n",
      "Epoch 88/100 — Step 1500 — Loss: 2.3666\n",
      "Epoch 88/100 — Step 2000 — Loss: 2.5905\n",
      "Epoch 88/100 — Step 2500 — Loss: 2.3365\n",
      "Epoch 88/100 — Step 3000 — Loss: 2.9498\n",
      "Epoch 88/100 — Step 3500 — Loss: 2.3708\n",
      "Epoch 88/100 — Step 4000 — Loss: 2.4008\n",
      "Epoch 88/100 — Step 4500 — Loss: 2.2668\n",
      "Epoch 88/100 — Step 5000 — Loss: 2.3687\n",
      "Epoch 88/100 — Step 5500 — Loss: 2.6280\n",
      "Epoch 88/100 — Step 6000 — Loss: 2.4075\n",
      "Epoch 88/100 — Step 6500 — Loss: 2.4533\n",
      "Epoch 88/100 — Step 7000 — Loss: 2.4714\n",
      "Epoch 88/100 — Step 7500 — Loss: 2.5865\n",
      "Epoch 88/100 — Step 8000 — Loss: 2.3083\n",
      "Epoch 88/100 — Step 8500 — Loss: 2.5200\n",
      "Epoch 88/100 — Step 9000 — Loss: 2.4428\n",
      "Epoch 88/100 — Step 9500 — Loss: 2.5487\n",
      "Epoch 88/100 — Step 10000 — Loss: 2.2566\n",
      "Epoch 88/100 — Step 10500 — Loss: 2.4229\n",
      "Epoch 88/100 — Step 11000 — Loss: 2.7116\n",
      "Epoch 88/100 — avg_loss: 2.4559, accuracy: 26.93%\n",
      "Epoch 89/100 — Step 500 — Loss: 2.4316\n",
      "Epoch 89/100 — Step 1000 — Loss: 2.3915\n",
      "Epoch 89/100 — Step 1500 — Loss: 2.3663\n",
      "Epoch 89/100 — Step 2000 — Loss: 2.5899\n",
      "Epoch 89/100 — Step 2500 — Loss: 2.3357\n",
      "Epoch 89/100 — Step 3000 — Loss: 2.9492\n",
      "Epoch 89/100 — Step 3500 — Loss: 2.3702\n",
      "Epoch 89/100 — Step 4000 — Loss: 2.4002\n",
      "Epoch 89/100 — Step 4500 — Loss: 2.2655\n",
      "Epoch 89/100 — Step 5000 — Loss: 2.3680\n",
      "Epoch 89/100 — Step 5500 — Loss: 2.6281\n",
      "Epoch 89/100 — Step 6000 — Loss: 2.4076\n",
      "Epoch 89/100 — Step 6500 — Loss: 2.4526\n",
      "Epoch 89/100 — Step 7000 — Loss: 2.4712\n",
      "Epoch 89/100 — Step 7500 — Loss: 2.5856\n",
      "Epoch 89/100 — Step 8000 — Loss: 2.3076\n",
      "Epoch 89/100 — Step 8500 — Loss: 2.5195\n",
      "Epoch 89/100 — Step 9000 — Loss: 2.4413\n",
      "Epoch 89/100 — Step 9500 — Loss: 2.5481\n",
      "Epoch 89/100 — Step 10000 — Loss: 2.2556\n",
      "Epoch 89/100 — Step 10500 — Loss: 2.4227\n",
      "Epoch 89/100 — Step 11000 — Loss: 2.7106\n",
      "Epoch 89/100 — avg_loss: 2.4552, accuracy: 26.95%\n",
      "Epoch 90/100 — Step 500 — Loss: 2.4302\n",
      "Epoch 90/100 — Step 1000 — Loss: 2.3918\n",
      "Epoch 90/100 — Step 1500 — Loss: 2.3660\n",
      "Epoch 90/100 — Step 2000 — Loss: 2.5894\n",
      "Epoch 90/100 — Step 2500 — Loss: 2.3348\n",
      "Epoch 90/100 — Step 3000 — Loss: 2.9487\n",
      "Epoch 90/100 — Step 3500 — Loss: 2.3697\n",
      "Epoch 90/100 — Step 4000 — Loss: 2.3997\n",
      "Epoch 90/100 — Step 4500 — Loss: 2.2643\n",
      "Epoch 90/100 — Step 5000 — Loss: 2.3673\n",
      "Epoch 90/100 — Step 5500 — Loss: 2.6281\n",
      "Epoch 90/100 — Step 6000 — Loss: 2.4077\n",
      "Epoch 90/100 — Step 6500 — Loss: 2.4520\n",
      "Epoch 90/100 — Step 7000 — Loss: 2.4709\n",
      "Epoch 90/100 — Step 7500 — Loss: 2.5846\n",
      "Epoch 90/100 — Step 8000 — Loss: 2.3069\n",
      "Epoch 90/100 — Step 8500 — Loss: 2.5191\n",
      "Epoch 90/100 — Step 9000 — Loss: 2.4398\n",
      "Epoch 90/100 — Step 9500 — Loss: 2.5476\n",
      "Epoch 90/100 — Step 10000 — Loss: 2.2546\n",
      "Epoch 90/100 — Step 10500 — Loss: 2.4226\n",
      "Epoch 90/100 — Step 11000 — Loss: 2.7097\n",
      "Epoch 90/100 — avg_loss: 2.4545, accuracy: 26.95%\n",
      "Epoch 91/100 — Step 500 — Loss: 2.4289\n",
      "Epoch 91/100 — Step 1000 — Loss: 2.3920\n",
      "Epoch 91/100 — Step 1500 — Loss: 2.3657\n",
      "Epoch 91/100 — Step 2000 — Loss: 2.5888\n",
      "Epoch 91/100 — Step 2500 — Loss: 2.3341\n",
      "Epoch 91/100 — Step 3000 — Loss: 2.9482\n",
      "Epoch 91/100 — Step 3500 — Loss: 2.3692\n",
      "Epoch 91/100 — Step 4000 — Loss: 2.3991\n",
      "Epoch 91/100 — Step 4500 — Loss: 2.2630\n",
      "Epoch 91/100 — Step 5000 — Loss: 2.3665\n",
      "Epoch 91/100 — Step 5500 — Loss: 2.6281\n",
      "Epoch 91/100 — Step 6000 — Loss: 2.4078\n",
      "Epoch 91/100 — Step 6500 — Loss: 2.4514\n",
      "Epoch 91/100 — Step 7000 — Loss: 2.4706\n",
      "Epoch 91/100 — Step 7500 — Loss: 2.5837\n",
      "Epoch 91/100 — Step 8000 — Loss: 2.3063\n",
      "Epoch 91/100 — Step 8500 — Loss: 2.5186\n",
      "Epoch 91/100 — Step 9000 — Loss: 2.4384\n",
      "Epoch 91/100 — Step 9500 — Loss: 2.5471\n",
      "Epoch 91/100 — Step 10000 — Loss: 2.2537\n",
      "Epoch 91/100 — Step 10500 — Loss: 2.4224\n",
      "Epoch 91/100 — Step 11000 — Loss: 2.7088\n",
      "Epoch 91/100 — avg_loss: 2.4539, accuracy: 26.96%\n",
      "Epoch 92/100 — Step 500 — Loss: 2.4275\n",
      "Epoch 92/100 — Step 1000 — Loss: 2.3922\n",
      "Epoch 92/100 — Step 1500 — Loss: 2.3655\n",
      "Epoch 92/100 — Step 2000 — Loss: 2.5882\n",
      "Epoch 92/100 — Step 2500 — Loss: 2.3333\n",
      "Epoch 92/100 — Step 3000 — Loss: 2.9477\n",
      "Epoch 92/100 — Step 3500 — Loss: 2.3687\n",
      "Epoch 92/100 — Step 4000 — Loss: 2.3986\n",
      "Epoch 92/100 — Step 4500 — Loss: 2.2618\n",
      "Epoch 92/100 — Step 5000 — Loss: 2.3658\n",
      "Epoch 92/100 — Step 5500 — Loss: 2.6282\n",
      "Epoch 92/100 — Step 6000 — Loss: 2.4079\n",
      "Epoch 92/100 — Step 6500 — Loss: 2.4508\n",
      "Epoch 92/100 — Step 7000 — Loss: 2.4704\n",
      "Epoch 92/100 — Step 7500 — Loss: 2.5828\n",
      "Epoch 92/100 — Step 8000 — Loss: 2.3056\n",
      "Epoch 92/100 — Step 8500 — Loss: 2.5181\n",
      "Epoch 92/100 — Step 9000 — Loss: 2.4370\n",
      "Epoch 92/100 — Step 9500 — Loss: 2.5466\n",
      "Epoch 92/100 — Step 10000 — Loss: 2.2527\n",
      "Epoch 92/100 — Step 10500 — Loss: 2.4222\n",
      "Epoch 92/100 — Step 11000 — Loss: 2.7079\n",
      "Epoch 92/100 — avg_loss: 2.4532, accuracy: 26.97%\n",
      "Epoch 93/100 — Step 500 — Loss: 2.4262\n",
      "Epoch 93/100 — Step 1000 — Loss: 2.3923\n",
      "Epoch 93/100 — Step 1500 — Loss: 2.3652\n",
      "Epoch 93/100 — Step 2000 — Loss: 2.5877\n",
      "Epoch 93/100 — Step 2500 — Loss: 2.3326\n",
      "Epoch 93/100 — Step 3000 — Loss: 2.9472\n",
      "Epoch 93/100 — Step 3500 — Loss: 2.3682\n",
      "Epoch 93/100 — Step 4000 — Loss: 2.3980\n",
      "Epoch 93/100 — Step 4500 — Loss: 2.2606\n",
      "Epoch 93/100 — Step 5000 — Loss: 2.3651\n",
      "Epoch 93/100 — Step 5500 — Loss: 2.6282\n",
      "Epoch 93/100 — Step 6000 — Loss: 2.4080\n",
      "Epoch 93/100 — Step 6500 — Loss: 2.4502\n",
      "Epoch 93/100 — Step 7000 — Loss: 2.4701\n",
      "Epoch 93/100 — Step 7500 — Loss: 2.5819\n",
      "Epoch 93/100 — Step 8000 — Loss: 2.3050\n",
      "Epoch 93/100 — Step 8500 — Loss: 2.5177\n",
      "Epoch 93/100 — Step 9000 — Loss: 2.4356\n",
      "Epoch 93/100 — Step 9500 — Loss: 2.5460\n",
      "Epoch 93/100 — Step 10000 — Loss: 2.2518\n",
      "Epoch 93/100 — Step 10500 — Loss: 2.4221\n",
      "Epoch 93/100 — Step 11000 — Loss: 2.7070\n",
      "Epoch 93/100 — avg_loss: 2.4526, accuracy: 26.98%\n",
      "Epoch 94/100 — Step 500 — Loss: 2.4249\n",
      "Epoch 94/100 — Step 1000 — Loss: 2.3925\n",
      "Epoch 94/100 — Step 1500 — Loss: 2.3649\n",
      "Epoch 94/100 — Step 2000 — Loss: 2.5871\n",
      "Epoch 94/100 — Step 2500 — Loss: 2.3318\n",
      "Epoch 94/100 — Step 3000 — Loss: 2.9467\n",
      "Epoch 94/100 — Step 3500 — Loss: 2.3677\n",
      "Epoch 94/100 — Step 4000 — Loss: 2.3975\n",
      "Epoch 94/100 — Step 4500 — Loss: 2.2594\n",
      "Epoch 94/100 — Step 5000 — Loss: 2.3644\n",
      "Epoch 94/100 — Step 5500 — Loss: 2.6282\n",
      "Epoch 94/100 — Step 6000 — Loss: 2.4081\n",
      "Epoch 94/100 — Step 6500 — Loss: 2.4496\n",
      "Epoch 94/100 — Step 7000 — Loss: 2.4698\n",
      "Epoch 94/100 — Step 7500 — Loss: 2.5810\n",
      "Epoch 94/100 — Step 8000 — Loss: 2.3044\n",
      "Epoch 94/100 — Step 8500 — Loss: 2.5172\n",
      "Epoch 94/100 — Step 9000 — Loss: 2.4342\n",
      "Epoch 94/100 — Step 9500 — Loss: 2.5455\n",
      "Epoch 94/100 — Step 10000 — Loss: 2.2508\n",
      "Epoch 94/100 — Step 10500 — Loss: 2.4220\n",
      "Epoch 94/100 — Step 11000 — Loss: 2.7062\n",
      "Epoch 94/100 — avg_loss: 2.4520, accuracy: 26.99%\n",
      "Epoch 95/100 — Step 500 — Loss: 2.4236\n",
      "Epoch 95/100 — Step 1000 — Loss: 2.3926\n",
      "Epoch 95/100 — Step 1500 — Loss: 2.3646\n",
      "Epoch 95/100 — Step 2000 — Loss: 2.5866\n",
      "Epoch 95/100 — Step 2500 — Loss: 2.3312\n",
      "Epoch 95/100 — Step 3000 — Loss: 2.9462\n",
      "Epoch 95/100 — Step 3500 — Loss: 2.3672\n",
      "Epoch 95/100 — Step 4000 — Loss: 2.3970\n",
      "Epoch 95/100 — Step 4500 — Loss: 2.2583\n",
      "Epoch 95/100 — Step 5000 — Loss: 2.3637\n",
      "Epoch 95/100 — Step 5500 — Loss: 2.6282\n",
      "Epoch 95/100 — Step 6000 — Loss: 2.4082\n",
      "Epoch 95/100 — Step 6500 — Loss: 2.4490\n",
      "Epoch 95/100 — Step 7000 — Loss: 2.4696\n",
      "Epoch 95/100 — Step 7500 — Loss: 2.5802\n",
      "Epoch 95/100 — Step 8000 — Loss: 2.3038\n",
      "Epoch 95/100 — Step 8500 — Loss: 2.5168\n",
      "Epoch 95/100 — Step 9000 — Loss: 2.4328\n",
      "Epoch 95/100 — Step 9500 — Loss: 2.5451\n",
      "Epoch 95/100 — Step 10000 — Loss: 2.2499\n",
      "Epoch 95/100 — Step 10500 — Loss: 2.4218\n",
      "Epoch 95/100 — Step 11000 — Loss: 2.7053\n",
      "Epoch 95/100 — avg_loss: 2.4514, accuracy: 27.00%\n",
      "Epoch 96/100 — Step 500 — Loss: 2.4223\n",
      "Epoch 96/100 — Step 1000 — Loss: 2.3927\n",
      "Epoch 96/100 — Step 1500 — Loss: 2.3643\n",
      "Epoch 96/100 — Step 2000 — Loss: 2.5861\n",
      "Epoch 96/100 — Step 2500 — Loss: 2.3305\n",
      "Epoch 96/100 — Step 3000 — Loss: 2.9458\n",
      "Epoch 96/100 — Step 3500 — Loss: 2.3667\n",
      "Epoch 96/100 — Step 4000 — Loss: 2.3964\n",
      "Epoch 96/100 — Step 4500 — Loss: 2.2572\n",
      "Epoch 96/100 — Step 5000 — Loss: 2.3630\n",
      "Epoch 96/100 — Step 5500 — Loss: 2.6282\n",
      "Epoch 96/100 — Step 6000 — Loss: 2.4083\n",
      "Epoch 96/100 — Step 6500 — Loss: 2.4484\n",
      "Epoch 96/100 — Step 7000 — Loss: 2.4693\n",
      "Epoch 96/100 — Step 7500 — Loss: 2.5793\n",
      "Epoch 96/100 — Step 8000 — Loss: 2.3032\n",
      "Epoch 96/100 — Step 8500 — Loss: 2.5163\n",
      "Epoch 96/100 — Step 9000 — Loss: 2.4315\n",
      "Epoch 96/100 — Step 9500 — Loss: 2.5446\n",
      "Epoch 96/100 — Step 10000 — Loss: 2.2490\n",
      "Epoch 96/100 — Step 10500 — Loss: 2.4217\n",
      "Epoch 96/100 — Step 11000 — Loss: 2.7044\n",
      "Epoch 96/100 — avg_loss: 2.4508, accuracy: 27.01%\n",
      "Epoch 97/100 — Step 500 — Loss: 2.4210\n",
      "Epoch 97/100 — Step 1000 — Loss: 2.3928\n",
      "Epoch 97/100 — Step 1500 — Loss: 2.3640\n",
      "Epoch 97/100 — Step 2000 — Loss: 2.5855\n",
      "Epoch 97/100 — Step 2500 — Loss: 2.3298\n",
      "Epoch 97/100 — Step 3000 — Loss: 2.9453\n",
      "Epoch 97/100 — Step 3500 — Loss: 2.3663\n",
      "Epoch 97/100 — Step 4000 — Loss: 2.3959\n",
      "Epoch 97/100 — Step 4500 — Loss: 2.2561\n",
      "Epoch 97/100 — Step 5000 — Loss: 2.3624\n",
      "Epoch 97/100 — Step 5500 — Loss: 2.6282\n",
      "Epoch 97/100 — Step 6000 — Loss: 2.4084\n",
      "Epoch 97/100 — Step 6500 — Loss: 2.4478\n",
      "Epoch 97/100 — Step 7000 — Loss: 2.4691\n",
      "Epoch 97/100 — Step 7500 — Loss: 2.5785\n",
      "Epoch 97/100 — Step 8000 — Loss: 2.3027\n",
      "Epoch 97/100 — Step 8500 — Loss: 2.5159\n",
      "Epoch 97/100 — Step 9000 — Loss: 2.4301\n",
      "Epoch 97/100 — Step 9500 — Loss: 2.5441\n",
      "Epoch 97/100 — Step 10000 — Loss: 2.2481\n",
      "Epoch 97/100 — Step 10500 — Loss: 2.4216\n",
      "Epoch 97/100 — Step 11000 — Loss: 2.7036\n",
      "Epoch 97/100 — avg_loss: 2.4502, accuracy: 27.02%\n",
      "Epoch 98/100 — Step 500 — Loss: 2.4198\n",
      "Epoch 98/100 — Step 1000 — Loss: 2.3929\n",
      "Epoch 98/100 — Step 1500 — Loss: 2.3638\n",
      "Epoch 98/100 — Step 2000 — Loss: 2.5850\n",
      "Epoch 98/100 — Step 2500 — Loss: 2.3292\n",
      "Epoch 98/100 — Step 3000 — Loss: 2.9449\n",
      "Epoch 98/100 — Step 3500 — Loss: 2.3658\n",
      "Epoch 98/100 — Step 4000 — Loss: 2.3954\n",
      "Epoch 98/100 — Step 4500 — Loss: 2.2550\n",
      "Epoch 98/100 — Step 5000 — Loss: 2.3617\n",
      "Epoch 98/100 — Step 5500 — Loss: 2.6282\n",
      "Epoch 98/100 — Step 6000 — Loss: 2.4085\n",
      "Epoch 98/100 — Step 6500 — Loss: 2.4473\n",
      "Epoch 98/100 — Step 7000 — Loss: 2.4688\n",
      "Epoch 98/100 — Step 7500 — Loss: 2.5776\n",
      "Epoch 98/100 — Step 8000 — Loss: 2.3021\n",
      "Epoch 98/100 — Step 8500 — Loss: 2.5154\n",
      "Epoch 98/100 — Step 9000 — Loss: 2.4288\n",
      "Epoch 98/100 — Step 9500 — Loss: 2.5436\n",
      "Epoch 98/100 — Step 10000 — Loss: 2.2472\n",
      "Epoch 98/100 — Step 10500 — Loss: 2.4215\n",
      "Epoch 98/100 — Step 11000 — Loss: 2.7028\n",
      "Epoch 98/100 — avg_loss: 2.4496, accuracy: 27.02%\n",
      "Epoch 99/100 — Step 500 — Loss: 2.4185\n",
      "Epoch 99/100 — Step 1000 — Loss: 2.3930\n",
      "Epoch 99/100 — Step 1500 — Loss: 2.3635\n",
      "Epoch 99/100 — Step 2000 — Loss: 2.5845\n",
      "Epoch 99/100 — Step 2500 — Loss: 2.3286\n",
      "Epoch 99/100 — Step 3000 — Loss: 2.9444\n",
      "Epoch 99/100 — Step 3500 — Loss: 2.3653\n",
      "Epoch 99/100 — Step 4000 — Loss: 2.3949\n",
      "Epoch 99/100 — Step 4500 — Loss: 2.2539\n",
      "Epoch 99/100 — Step 5000 — Loss: 2.3610\n",
      "Epoch 99/100 — Step 5500 — Loss: 2.6281\n",
      "Epoch 99/100 — Step 6000 — Loss: 2.4086\n",
      "Epoch 99/100 — Step 6500 — Loss: 2.4467\n",
      "Epoch 99/100 — Step 7000 — Loss: 2.4686\n",
      "Epoch 99/100 — Step 7500 — Loss: 2.5768\n",
      "Epoch 99/100 — Step 8000 — Loss: 2.3015\n",
      "Epoch 99/100 — Step 8500 — Loss: 2.5149\n",
      "Epoch 99/100 — Step 9000 — Loss: 2.4275\n",
      "Epoch 99/100 — Step 9500 — Loss: 2.5431\n",
      "Epoch 99/100 — Step 10000 — Loss: 2.2463\n",
      "Epoch 99/100 — Step 10500 — Loss: 2.4214\n",
      "Epoch 99/100 — Step 11000 — Loss: 2.7019\n",
      "Epoch 99/100 — avg_loss: 2.4490, accuracy: 27.03%\n",
      "Epoch 100/100 — Step 500 — Loss: 2.4173\n",
      "Epoch 100/100 — Step 1000 — Loss: 2.3930\n",
      "Epoch 100/100 — Step 1500 — Loss: 2.3632\n",
      "Epoch 100/100 — Step 2000 — Loss: 2.5840\n",
      "Epoch 100/100 — Step 2500 — Loss: 2.3280\n",
      "Epoch 100/100 — Step 3000 — Loss: 2.9440\n",
      "Epoch 100/100 — Step 3500 — Loss: 2.3649\n",
      "Epoch 100/100 — Step 4000 — Loss: 2.3944\n",
      "Epoch 100/100 — Step 4500 — Loss: 2.2529\n",
      "Epoch 100/100 — Step 5000 — Loss: 2.3604\n",
      "Epoch 100/100 — Step 5500 — Loss: 2.6281\n",
      "Epoch 100/100 — Step 6000 — Loss: 2.4087\n",
      "Epoch 100/100 — Step 6500 — Loss: 2.4462\n",
      "Epoch 100/100 — Step 7000 — Loss: 2.4683\n",
      "Epoch 100/100 — Step 7500 — Loss: 2.5760\n",
      "Epoch 100/100 — Step 8000 — Loss: 2.3010\n",
      "Epoch 100/100 — Step 8500 — Loss: 2.5145\n",
      "Epoch 100/100 — Step 9000 — Loss: 2.4263\n",
      "Epoch 100/100 — Step 9500 — Loss: 2.5427\n",
      "Epoch 100/100 — Step 10000 — Loss: 2.2454\n",
      "Epoch 100/100 — Step 10500 — Loss: 2.4212\n",
      "Epoch 100/100 — Step 11000 — Loss: 2.7011\n",
      "Epoch 100/100 — avg_loss: 2.4484, accuracy: 27.04%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from from_scratch_transformer.transformer import Transformer\n",
    "from from_scratch_transformer.layers import Input, Softmax\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "if torch.cuda.is_available():\n",
    "     torch.set_default_device(0)\n",
    "     print(\"Running on the GPU\")\n",
    "else:\n",
    "     print(\"Running on the CPU\")\n",
    "\n",
    "# Hyperparameters\n",
    "seq_len       = 100    \n",
    "epochs        = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Model dimensions\n",
    "d_model    = 1600      # embedding size\n",
    "num_heads  = 8      # Number of heads in each attention block\n",
    "d_ff       = 2048 * 2     # FF hidden dim \n",
    "num_layers = 2     # number of decoder blocks\n",
    "\n",
    "# Load data\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Build vocab\n",
    "chars = sorted(set(text))\n",
    "vocab_size = len(chars)\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "\n",
    "# Encode text as ids\n",
    "data = torch.tensor([stoi[ch] for ch in text], dtype=torch.long)\n",
    "\n",
    "def get_batch(start):\n",
    "    x = data[start : start + seq_len]          # [T]\n",
    "    y = data[start + 1 : start + 1 + seq_len]  # [T]\n",
    "    return x, y\n",
    "\n",
    "# i nit model\n",
    "model = Transformer(vocab_size, d_model, num_heads, d_ff, num_layers)\n",
    "all_preds = []\n",
    "# Training loop\n",
    "for epoch in range(1, epochs + 1):\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    steps = 0\n",
    "    for i in range(0, data.size(0) - seq_len - 1, seq_len):\n",
    "        x_seq, y_seq = get_batch(i)   \n",
    "\n",
    "        # Forward\n",
    "        out_lin = model.forward(x_seq)   # out_lin.output: [T, V]\n",
    "        logits  = out_lin.output         \n",
    "        T, V    = logits.shape\n",
    "\n",
    "        # Compute predictions\n",
    "        preds = logits.argmax(dim=1)    \n",
    "        # all_preds.append(preds)\n",
    "        # print(preds)\n",
    "        next_char = itos[preds[-1].item()]\n",
    "        all_preds.append(next_char)\n",
    "        total_correct += (preds == y_seq).sum().item()\n",
    "        total_tokens  += T\n",
    "\n",
    "        # one hot encode targets\n",
    "        target_onehot = torch.zeros_like(logits)\n",
    "        target_onehot[torch.arange(T), y_seq] = 1.0\n",
    "        target_layer = Input(T, V)\n",
    "        target_layer.set(target_onehot)\n",
    "\n",
    "        # Loss\n",
    "        loss_layer = Softmax(out_lin, target_layer)\n",
    "        loss_layer.forward()\n",
    "        loss = loss_layer.output\n",
    "\n",
    "        # Backward\n",
    "        loss_layer.backward()\n",
    "        model.backward()\n",
    "\n",
    "        # Update and clear\n",
    "        model.step(learning_rate)\n",
    "        loss_layer.clear_grad()\n",
    "        model.clear_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        steps += 1\n",
    "        if steps % 500 == 0:\n",
    "            print(f'Epoch {epoch}/{epochs} — Step {steps} — Loss: {loss.item():.4f}')\n",
    "\n",
    "    avg_loss = total_loss / steps if steps > 0 else float('nan')\n",
    "    accuracy = total_correct / total_tokens if total_tokens > 0 else float('nan')\n",
    "    print(f'Epoch {epoch}/{epochs} — avg_loss: {avg_loss:.4f}, accuracy: {accuracy:.2%}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Letter Pred Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(all_preds, bins = 35)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character wise completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def generate(prompt: str, max_gen: int = 100, temperature: float = 1.0) -> str:\n",
    "    # Encode prompt to token ids\n",
    "    context = torch.tensor([stoi.get(ch, 0) for ch in prompt], dtype=torch.long)\n",
    "\n",
    "    for _ in range(max_gen):\n",
    "        # Forward pass\n",
    "        out_lin = model.forward(context)\n",
    "        logits = out_lin.output   # shape: (seq_len, vocab_size)\n",
    "\n",
    "        # Take logits for the last position and apply temperature scaling\n",
    "        next_logits = logits[-1] / (temperature if temperature > 0 else 1e-8)\n",
    "\n",
    "        # Convert to probabilities\n",
    "        probs = F.softmax(next_logits, dim=-1)\n",
    "\n",
    "        # Sample from the distribution\n",
    "        next_id = int(torch.multinomial(probs, num_samples=1).item())\n",
    "\n",
    "        # Append to context\n",
    "        context = torch.cat([context, torch.tensor([next_id], dtype=torch.long)])\n",
    "\n",
    "    # Decode only the newly generated tokens\n",
    "    generated_ids = context[len(prompt):].tolist()\n",
    "    return ''.join(itos[i] for i in generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Temperature 0.2 ---\n",
      "Hello, what is your name? My name is menthe momommmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n",
      "\n",
      "--- Temperature 0.8 ---\n",
      "Hello, what is your name? My name is wthillowwin ouhanthonofomewoe wowithath whe the th\n",
      "\n",
      "--- Temperature 1.5 ---\n",
      "Hello, what is your name? My name is pa\n",
      "voo in louAe f ?ouour mo a lloopccooe,otuooour\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Hello, what is your name? My name is \"\n",
    "max_gen = 50\n",
    "\n",
    "for temp in [0.2, 0.8, 1.5]:\n",
    "    continuation = generate(prompt, max_gen=max_gen, temperature=temp)\n",
    "    print(f\"\\n--- Temperature {temp} ---\")\n",
    "    print(prompt + continuation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These bad results are due to the lack of training time. Chat GPT trains for months, while this only trained for an hour or so."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
